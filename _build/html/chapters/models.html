

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>11. Probabilistic models &#8212; Mathematical Statistics with a View Toward Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/models';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12. Statistics and estimators" href="stats-estimators.html" />
    <link rel="prev" title="10. More probability theory" href="more-prob.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Mathematical Statistics with a View Toward Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preview.html">1. Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-spaces.html">2. Probability spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="rules-of-prob.html">3. Rules of probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="random-variables.html">4. Random variables, expected values, variances</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples-of-rvs.html">5. Examples of random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="theory-to-practice.html">6. Connecting theory to practice: data and samples</a></li>
<li class="toctree-l1"><a class="reference internal" href="random-vectors.html">7. Random vectors; joint, marginal and conditional distributions; independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="covar-correl.html">8. Covariance and correlation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples-of-random-vecs.html">9. Examples of random vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="more-prob.html">10. More probability theory</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">11. Probabilistic models</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats-estimators.html">12. Statistics and estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="asymptotic.html">13. The asymptotic theory: the LLN and CLT</a></li>
<li class="toctree-l1"><a class="reference internal" href="more-samp-dist.html">14. More sampling distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="CIs.html">15. Confidence intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyp-test.html">16. Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="lin-reg.html">17. Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="bib.html">18. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jmyers7/stats-book-materials" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probabilistic models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-examples">11.1. First examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#head-to-tail-nodes">11.1.1. Head-to-tail nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tail-to-tail-nodes">11.1.2. Tail-to-tail nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#head-to-head-nodes">11.1.3. Head-to-head nodes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dags-and-pgms">11.2. DAGs and PGMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-and-d-separation">11.3. Independence and <span class="math notranslate nohighlight">\(d\)</span>-separation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-examples">11.4. More examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">11.4.1. Linear regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">11.4.2. Logistic regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-models">11.4.3. Markov models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-mixture-models">11.4.4. Gaussian mixture models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-based-optimization">11.5. Gradient-based optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-gradient-descent">11.5.1. Vanilla gradient descent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd">11.5.2. Stochastic gradient descent (SGD)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle">11.6. Maximum likelihood estimation (MLE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-basics">11.6.1. The basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-linear-regression">11.6.2. MLE for linear regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-logistic-regression">11.6.3. MLE for logistic regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-markov-models">11.6.4. MLE for Markov models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization-em">11.7. Expectation maximization (EM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-em">11.7.1. Vanilla EM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-em-mcem">11.7.2. Monte Carlo EM (MCEM)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#em-for-gaussian-mixture-models">11.7.3. EM for Gaussian mixture models</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probabilistic-models">
<span id="prob-models"></span><h1><span class="section-number">11. </span>Probabilistic models<a class="headerlink" href="#probabilistic-models" title="Permalink to this heading">#</a></h1>
<p><strong>THIS CHAPTER IS CURRENTLY UNDER CONSTRUCTION!!!</strong></p>
<section id="first-examples">
<h2><span class="section-number">11.1. </span>First examples<a class="headerlink" href="#first-examples" title="Permalink to this heading">#</a></h2>
<section id="head-to-tail-nodes">
<h3><span class="section-number">11.1.1. </span>Head-to-tail nodes<a class="headerlink" href="#head-to-tail-nodes" title="Permalink to this heading">#</a></h3>
</section>
<section id="tail-to-tail-nodes">
<h3><span class="section-number">11.1.2. </span>Tail-to-tail nodes<a class="headerlink" href="#tail-to-tail-nodes" title="Permalink to this heading">#</a></h3>
</section>
<section id="head-to-head-nodes">
<h3><span class="section-number">11.1.3. </span>Head-to-head nodes<a class="headerlink" href="#head-to-head-nodes" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="dags-and-pgms">
<h2><span class="section-number">11.2. </span>DAGs and PGMs<a class="headerlink" href="#dags-and-pgms" title="Permalink to this heading">#</a></h2>
<p>At the most basic level, a <em>directed graph</em> <span class="math notranslate nohighlight">\(G\)</span> consists of two sets <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(E\)</span> of <em>vertices</em> and <em>edges</em>. The vertices are visualized as nodes, and the edges are arrows that run between the nodes. For example, consider the following graph:</p>
<a class="reference internal image-reference" href="../_images/graph-01.svg"><img alt="../_images/graph-01.svg" class="align-center" src="../_images/graph-01.svg" width="90%" /></a>
<p> </p>
<p>This graph consists of five vertices and five edges:</p>
<div class="math notranslate nohighlight">
\[
V = \{v_1,v_2,v_3,v_4,v_5\}, \quad E = \{e_1,e_2,e_3,e_4,e_5\}.
\]</div>
<p>Notice that this graph is <em>acyclic</em>, which means that beginning at any given node, there is no (directed) path along the edges that returns to the original node. Thus, our graph <span class="math notranslate nohighlight">\(G\)</span> is an example of a <em>directed acyclic graph</em>, or <em>DAG</em> for short.</p>
<p>If there is a directed edge <span class="math notranslate nohighlight">\(v_i \to v_j\)</span> from a node <span class="math notranslate nohighlight">\(v_i\)</span> to a node <span class="math notranslate nohighlight">\(v_j\)</span>, then <span class="math notranslate nohighlight">\(v_i\)</span> is said to be a <em>parent</em> of <span class="math notranslate nohighlight">\(v_j\)</span> and <span class="math notranslate nohighlight">\(v_j\)</span> is called a <em>child</em> of <span class="math notranslate nohighlight">\(v_i\)</span>. For example, in our graph <span class="math notranslate nohighlight">\(G\)</span> above, the set of parents of <span class="math notranslate nohighlight">\(v_4\)</span> is <span class="math notranslate nohighlight">\(\{v_1,v_2\}\)</span>, while the set of children of <span class="math notranslate nohighlight">\(v_4\)</span> is <span class="math notranslate nohighlight">\(\{v_5\}\)</span>.</p>
<p>More generally, if there exists a directed path from <span class="math notranslate nohighlight">\(v_i\)</span> to <span class="math notranslate nohighlight">\(v_j\)</span> of any length, say</p>
<div class="math notranslate nohighlight">
\[
v_i \to \cdots \to v_j,
\]</div>
<p>then <span class="math notranslate nohighlight">\(v_j\)</span> is called a <em>descendant</em> of <span class="math notranslate nohighlight">\(v_i\)</span>. Thus, <span class="math notranslate nohighlight">\(v_j\)</span> is a child of <span class="math notranslate nohighlight">\(v_i\)</span> if there exists a directed path of length <span class="math notranslate nohighlight">\(1\)</span>. In our graph above, the node <span class="math notranslate nohighlight">\(v_5\)</span> is a descendant of <span class="math notranslate nohighlight">\(v_2\)</span> which is not a child.</p>
<p>The vertex set of a graph can be any set whatsoever; in particular, we can take the vertex set of a DAG to be a set of random variables <span class="math notranslate nohighlight">\(V = \{X_1,\ldots,X_n\}\)</span>. In our running example from the previous section, we might imagine that our graph has vertex set consisting of five random variables:</p>
<a class="reference internal image-reference" href="../_images/graph-02.svg"><img alt="../_images/graph-02.svg" class="align-center" src="../_images/graph-02.svg" width="90%" /></a>
<p> </p>
<p>I have omitted the edge labels for clarity, which I will continue to do in what follows.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 11.1 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(V = \{X_1,\ldots,X_n\}\)</span> be a collection of random variables, <span class="math notranslate nohighlight">\(G\)</span> a graph with vertex set <span class="math notranslate nohighlight">\(V\)</span>, and <span class="math notranslate nohighlight">\(p(x_1,\ldots,x_n)\)</span> the joint probability function. We shall say that <span class="math notranslate nohighlight">\(G\)</span> <em>represents</em> the joint probability distribution, or that <span class="math notranslate nohighlight">\(p\)</span> <em>factors over <span class="math notranslate nohighlight">\(G\)</span></em>, if</p>
<div class="math notranslate nohighlight">
\[
p(x_1,\ldots,x_n) = \prod_{i=1}^n p(x_i | \text{parents of $x_i$}).
\]</div>
</section>
</div><p>Note that I am intentionally confusing an observed value <span class="math notranslate nohighlight">\(x_i\)</span> of a random variable <span class="math notranslate nohighlight">\(X_i\)</span> with the random variable itself, so that the “parents of <span class="math notranslate nohighlight">\(x_i\)</span>” actually makes sense.</p>
<p>In our running example, the graph <span class="math notranslate nohighlight">\(G\)</span> represents the joint probability distribution provided that</p>
<div class="math notranslate nohighlight">
\[
p(x_1,x_2,x_3,x_4,x_5) = p(x_1|x_2)p(x_2)p(x_3|x_2)p(x_4|x_1,x_2)p(x_5|x_4).
\]</div>
<p>Notice that the random variable <span class="math notranslate nohighlight">\(X_2\)</span> has no parents in <span class="math notranslate nohighlight">\(G\)</span>, so that the marginal probability function <span class="math notranslate nohighlight">\(p(x_2)\)</span> serves in place of a conditional distribution.</p>
</section>
<section id="independence-and-d-separation">
<h2><span class="section-number">11.3. </span>Independence and <span class="math notranslate nohighlight">\(d\)</span>-separation<a class="headerlink" href="#independence-and-d-separation" title="Permalink to this heading">#</a></h2>
</section>
<section id="more-examples">
<h2><span class="section-number">11.4. </span>More examples<a class="headerlink" href="#more-examples" title="Permalink to this heading">#</a></h2>
<section id="linear-regression">
<h3><span class="section-number">11.4.1. </span>Linear regression<a class="headerlink" href="#linear-regression" title="Permalink to this heading">#</a></h3>
<p>The goal of <em>linear regression</em> is to model an IID random sample <span class="math notranslate nohighlight">\(\{Y^{(i)}\}_{i=1}^m\)</span> of normally distributed variables based on a sequence <span class="math notranslate nohighlight">\(\{\mathbf{x}^{(i)}\}_{i=1}^n \subset \mathbb{R}^n\)</span> of deterministic vectors. Here are the precise details:</p>
<div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 11.2 </span></p>
<section class="definition-content" id="proof-content">
<p>A <em>linear regression model</em> is a probabilistic graphical model whose underlying graph is of the form</p>
<a class="reference internal image-reference" href="../_images/lin-reg-01.svg"><img alt="../_images/lin-reg-01.svg" class="align-center" src="../_images/lin-reg-01.svg" width="50%" /></a>
<p> </p>
<p>The components of the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol\beta=(\beta_0,\beta_1,\ldots,\beta_n)\)</span> may be any real numbers, while <span class="math notranslate nohighlight">\(\sigma^2\)</span> must be positive (in particular, not zero). For each <span class="math notranslate nohighlight">\(i=1,\ldots,m\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
Y^{(i)} ; x^{(i)}, \boldsymbol\beta,\sigma^2 \sim \mathcal{N}\big(\mu^{(i)},\sigma^2\big),
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\mu^{(i)} = \beta_0 + \beta_1 x_1^{(i)} + \cdots + \beta_n x_n^{(i)}.
\]</div>
<p>The (components of the) vectors <span class="math notranslate nohighlight">\(\{x^{(i)}\}\)</span> are referred to as the <em>predictors</em>, <em>regressors</em>, <em>explanatory variables</em>, or <em>independent variables</em>, while the random variables <span class="math notranslate nohighlight">\(\{Y^{(i)}\}\)</span> are called the <em>response variables</em> or the <em>dependent variables</em>. In the case that <span class="math notranslate nohighlight">\(n=1\)</span>, so that the predictors are real numbers, the model is called a <em>simple linear regression model</em>; otherwise, it is called a <em>multiple linear regression model</em>.</p>
</section>
</div><p>It follows that the joint density function of a linear regression model factors as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p(\mathbf{y}; \mathbf{x}^{(1)},\ldots,\mathbf{x}^{(m)}, \boldsymbol\beta,\sigma^2) &amp;= \prod_{i=1}^m p\big( y^{(i)}; \mathbf{x}^{(i)}, \boldsymbol\beta,\sigma^2\big) \\
&amp;= \prod_{i=1}^m \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left[ -\frac{1}{2\sigma^2}\big(y^{(i)} - \mu^{(i)}\big)^2\right] \\
&amp;= \frac{1}{\big(2\pi \sigma^2\big)^{m/2}} \exp \left[ - \frac{1}{2\sigma^2} \sum_{i=1}^m \big( y^{(i)} - \mu^{(i)}\big)^2 \right].
\end{align*}\]</div>
<p>Note that</p>
<div class="math notranslate nohighlight">
\[
E\big(Y^{(i)}\big) = \mu^{(i)} = \beta_0 + \beta_1 x_1^{(i)} + \cdots + \beta_n x_n^{(i)},
\]</div>
<p>and so a linear regression model assumes (among other things) that the means of the response variables are linearly related to the regressors through the function</p>
<div class="math notranslate nohighlight" id="equation-lin-reg-line-eqn">
<span class="eqno">(11.1)<a class="headerlink" href="#equation-lin-reg-line-eqn" title="Permalink to this equation">#</a></span>\[
\mu = \beta_0 + \beta_1x_1 + \cdots + \beta_n x_n.
\]</div>
<p>The parameter <span class="math notranslate nohighlight">\(\beta_0\)</span> is often called the <em>intercept coefficient</em>, while the other <span class="math notranslate nohighlight">\(\beta_j\)</span>’s (for <span class="math notranslate nohighlight">\(j&gt;0\)</span>) are called <em>slope coefficients</em> since they are exactly the (infinitesimal) slopes:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mu}{\partial x_j} = \beta_j.
\]</div>
<p>The line <a class="reference internal" href="#equation-lin-reg-line-eqn">(11.1)</a> is often called the <em>regression line</em> of the model, and it is often displayed in a scatter plot with observed data. For example, suppose we consider the Ames housing data from the <a href="https://github.com/jmyers7/stats-book-materials/tree/main/programming-assignments">third programming assignment</a>. In this dataset, we have two columns of observations on <em>price</em> (measured in thousands of US dollars) and <em>area</em> (measured in square feet):</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/jmyers7/stats-book-materials/main/data/data-3-1.csv&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">])</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>area</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1656</td>
      <td>215.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>896</td>
      <td>105.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1329</td>
      <td>172.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2110</td>
      <td>244.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1629</td>
      <td>189.9</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2925</th>
      <td>1003</td>
      <td>142.5</td>
    </tr>
    <tr>
      <th>2926</th>
      <td>902</td>
      <td>131.0</td>
    </tr>
    <tr>
      <th>2927</th>
      <td>970</td>
      <td>132.0</td>
    </tr>
    <tr>
      <th>2928</th>
      <td>1389</td>
      <td>170.0</td>
    </tr>
    <tr>
      <th>2929</th>
      <td>2000</td>
      <td>188.0</td>
    </tr>
  </tbody>
</table>
<p>2930 rows × 2 columns</p>
</div></div></figure>
</div>
</div>
<p>We might believe that the price observations <span class="math notranslate nohighlight">\(y^{(1)},\ldots,y^{2{,}930}\)</span> come from an IID random sample</p>
<div class="math notranslate nohighlight">
\[
Y^{(1)},\ldots,Y^{(2{,}930)}
\]</div>
<p>that may be predicted by the area observations <span class="math notranslate nohighlight">\(x^{(1)},\ldots,x^{(2{,}930)}\)</span> through a simple linear regression model. Based on this dataset, as we will see below (in <a class="reference internal" href="#mle-lin-reg-sec"><span class="std std-numref">Section 11.6.2</span></a>), it is possible to choose an “optimal” value for the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol\beta = (\beta_0,\beta_1)\)</span> leading to a “best fit.” Using these values of <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>, we may plot the regression line <a class="reference internal" href="#equation-lin-reg-line-eqn">(11.1)</a> along with the data in a scatter plot:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline.backend_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../aux-files/custom_style_light.mplstyle&#39;</span><span class="p">)</span>
<span class="n">magenta</span> <span class="o">=</span> <span class="s1">&#39;#FD46FC&#39;</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;price ~ area&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">beta_0</span><span class="p">,</span> <span class="n">beta_1</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">params</span>

<span class="n">min_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">max_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_data</span><span class="p">,</span> <span class="n">max_data</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;price&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">grid</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">magenta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/b6b4243cf8ddbbdcf0230ff77443b7dc6b723a43152ec2c649e2c98daf10a853.svg"><img alt="../_images/b6b4243cf8ddbbdcf0230ff77443b7dc6b723a43152ec2c649e2c98daf10a853.svg" src="../_images/b6b4243cf8ddbbdcf0230ff77443b7dc6b723a43152ec2c649e2c98daf10a853.svg" width="70%" /></a>
</figure>
</div>
</div>
<p>In general, the random variables</p>
<div class="math notranslate nohighlight">
\[
\epsilon^{(i)} = Y^{(i)} - \mu^{(i)}
\]</div>
<p>in a linear regression model are called the <em>error terms</em>. Note then that</p>
<div class="math notranslate nohighlight">
\[
Y^{(i)} = \beta_0 + \beta_1 x_1^{(i)} + \cdots + \beta_n x_n^{(i)} + \epsilon^{(i)}
\]</div>
<p>and <span class="math notranslate nohighlight">\(\epsilon^{(i)} \sim \mathcal{N}\big( 0,\sigma^2\big)\)</span> for each <span class="math notranslate nohighlight">\(i=1,\ldots,m\)</span>. The assumption built into the linear regression model that the error terms all share the same variance is called <em>homoscedasticity</em>. If we have observed values <span class="math notranslate nohighlight">\(y^{(1)},\ldots,y^{(m)}\)</span>, then the differences</p>
<div class="math notranslate nohighlight" id="equation-resid-eqn">
<span class="eqno">(11.2)<a class="headerlink" href="#equation-resid-eqn" title="Permalink to this equation">#</a></span>\[
y^{(i)} - \hat{y}^{(i)}
\]</div>
<p>are observed values of the error terms, where</p>
<div class="math notranslate nohighlight">
\[
\hat{y}^{(i)} \stackrel{\text{def}}{=} \mu^{(i)} = \beta_0 + \beta_1x_1^{(i)} + \cdots + \beta_n x_n^{(i)}
\]</div>
<p>are the <em>predicted values</em> of the <span class="math notranslate nohighlight">\(y^{(i)}\)</span>’s. The differences <a class="reference internal" href="#equation-resid-eqn">(11.2)</a> are called the <em>residuals</em> of the observed values.</p>
<p>Based on the scatter plot above, it is apparent that the homoscedasticity assumption is violated in the Ames dataset. This is made even more apparent by plotting the residuals against the predictor variable:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resid</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">resid</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">resid</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;area&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;residuals&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/c60f1fd41336c3d1da714896bd955db7b4d4510aa1d43b8c07ee7427f2500b5f.svg"><img alt="../_images/c60f1fd41336c3d1da714896bd955db7b4d4510aa1d43b8c07ee7427f2500b5f.svg" src="../_images/c60f1fd41336c3d1da714896bd955db7b4d4510aa1d43b8c07ee7427f2500b5f.svg" width="70%" /></a>
</figure>
</div>
</div>
<p>Indeed, the distributions of the residuals appear to widen as the area variable increases.</p>
<p>As with the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>, it is also possible to estimate an “optimal” value of the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> in the linear regression model for the Ames dataset. Given these parameters, we may then generate new datasets by sampling from the normal distributions</p>
<div class="math notranslate nohighlight">
\[
\mathcal{N}\big(\mu^{(i)}, \sigma^2\big)
\]</div>
<p>for each <span class="math notranslate nohighlight">\(i=1,2,\ldots,2{,}930\)</span>. It is interesting to produce scatter plots of a few generated datasets and compare their shape to the real dataset above:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">y_gen</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">2930</span><span class="p">)</span>
    <span class="n">df_gen</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;area&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="n">y_gen</span><span class="p">})</span>
    <span class="n">df_gen</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;price&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">grid</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">magenta</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 1&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 2&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 3&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 4&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/51bffc05bae9c20a4a4db65a51b5533af1f20c5a0529909173d7240c88362e93.svg"><img alt="../_images/51bffc05bae9c20a4a4db65a51b5533af1f20c5a0529909173d7240c88362e93.svg" src="../_images/51bffc05bae9c20a4a4db65a51b5533af1f20c5a0529909173d7240c88362e93.svg" width="100%" /></a>
</figure>
</div>
</div>
<p>The lines in these plots are copies of the original regression line. The residuals for these generated datasets look as follows:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">y_gen</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">2930</span><span class="p">)</span>
    <span class="n">df_gen</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;area&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="n">y_gen</span><span class="p">})</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_gen</span><span class="p">)</span>
    <span class="n">resid</span> <span class="o">=</span> <span class="n">y_gen</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">resid</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;area&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;residuals&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 1&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 2&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 3&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;generated dataset 4&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/e65e40ab7a1afcdd26d6fe37e97078b3c72424d79356d4d3e67c9be3535f3384.svg"><img alt="../_images/e65e40ab7a1afcdd26d6fe37e97078b3c72424d79356d4d3e67c9be3535f3384.svg" src="../_images/e65e40ab7a1afcdd26d6fe37e97078b3c72424d79356d4d3e67c9be3535f3384.svg" width="100%" /></a>
</figure>
</div>
</div>
<p>This is a form of <em>model checking</em>: By generating new data from the model and comparing to the original data, we are checking to see how well our model matches the real data.</p>
</section>
<section id="logistic-regression">
<h3><span class="section-number">11.4.2. </span>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading">#</a></h3>
<p>The only difference between the linear regression models studied in the previous section and the <em>logistic regression models</em> studied in this one are the assumed forms of distributions of the IID random sample.</p>
<div class="proof definition admonition" id="definition-2">
<p class="admonition-title"><span class="caption-number">Definition 11.3 </span></p>
<section class="definition-content" id="proof-content">
<p>A <em>logistic regression model</em> is a probabilistic graphical model whose underlying graph is of the form</p>
<a class="reference internal image-reference" href="../_images/log-reg-01.svg"><img alt="../_images/log-reg-01.svg" class="align-center" src="../_images/log-reg-01.svg" width="50%" /></a>
<p> </p>
<p>The deterministic vectors <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)} = \big(x_1^{(i)},\ldots,x_n^{(n)}\big)\)</span> have no restrictions on their componenets, as well as the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol\beta=(\beta_0,\beta_1,\ldots,\beta_n)\)</span>. For each <span class="math notranslate nohighlight">\(i=1,\ldots,m\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
Y^{(i)} ; \mathbf{x}^{(i)}, \boldsymbol\beta \sim \mathcal{B}er\big(\phi^{(i)}\big),
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\phi^{(i)} = \sigma\big(\beta_0 + \beta_1 x_1^{(i)} + \cdots + \beta_n x_n^{(i)}\big)
\]</div>
<p>and <span class="math notranslate nohighlight">\(\sigma: \mathbb{R} \to \mathbb{R}\)</span> is the <em>logistic function</em> (or <em>sigmoid function</em>) defined as</p>
<div class="math notranslate nohighlight">
\[
\sigma(z) = \frac{1}{1+e^{-z}}.
\]</div>
</section>
</div><p>It follows that the joint density function of a logistic regression model factors as</p>
<div class="math notranslate nohighlight">
\[
p( \mathbf{y}; \mathbf{x}^{(1)},\ldots, \mathbf{x}^{(m)}, \boldsymbol\beta) = \prod_{i=1}^m p\big( y^{(i)}; \mathbf{x}^{(i)}, \boldsymbol\beta\big) = \prod_{i=1}^m \big(\phi^{(i)}\big)^{y^{(i)}} \big(1 - \phi^{(i)}\big)^{1 - \phi^{(i)}}.
\]</div>
</section>
<section id="markov-models">
<h3><span class="section-number">11.4.3. </span>Markov models<a class="headerlink" href="#markov-models" title="Permalink to this heading">#</a></h3>
</section>
<section id="gaussian-mixture-models">
<h3><span class="section-number">11.4.4. </span>Gaussian mixture models<a class="headerlink" href="#gaussian-mixture-models" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="gradient-based-optimization">
<h2><span class="section-number">11.5. </span>Gradient-based optimization<a class="headerlink" href="#gradient-based-optimization" title="Permalink to this heading">#</a></h2>
<section id="vanilla-gradient-descent">
<h3><span class="section-number">11.5.1. </span>Vanilla gradient descent<a class="headerlink" href="#vanilla-gradient-descent" title="Permalink to this heading">#</a></h3>
</section>
<section id="stochastic-gradient-descent-sgd">
<h3><span class="section-number">11.5.2. </span>Stochastic gradient descent (SGD)<a class="headerlink" href="#stochastic-gradient-descent-sgd" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="maximum-likelihood-estimation-mle">
<h2><span class="section-number">11.6. </span>Maximum likelihood estimation (MLE)<a class="headerlink" href="#maximum-likelihood-estimation-mle" title="Permalink to this heading">#</a></h2>
<section id="the-basics">
<h3><span class="section-number">11.6.1. </span>The basics<a class="headerlink" href="#the-basics" title="Permalink to this heading">#</a></h3>
</section>
<section id="mle-for-linear-regression">
<span id="mle-lin-reg-sec"></span><h3><span class="section-number">11.6.2. </span>MLE for linear regression<a class="headerlink" href="#mle-for-linear-regression" title="Permalink to this heading">#</a></h3>
</section>
<section id="mle-for-logistic-regression">
<h3><span class="section-number">11.6.3. </span>MLE for logistic regression<a class="headerlink" href="#mle-for-logistic-regression" title="Permalink to this heading">#</a></h3>
</section>
<section id="mle-for-markov-models">
<h3><span class="section-number">11.6.4. </span>MLE for Markov models<a class="headerlink" href="#mle-for-markov-models" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="expectation-maximization-em">
<h2><span class="section-number">11.7. </span>Expectation maximization (EM)<a class="headerlink" href="#expectation-maximization-em" title="Permalink to this heading">#</a></h2>
<section id="vanilla-em">
<h3><span class="section-number">11.7.1. </span>Vanilla EM<a class="headerlink" href="#vanilla-em" title="Permalink to this heading">#</a></h3>
</section>
<section id="monte-carlo-em-mcem">
<h3><span class="section-number">11.7.2. </span>Monte Carlo EM (MCEM)<a class="headerlink" href="#monte-carlo-em-mcem" title="Permalink to this heading">#</a></h3>
</section>
<section id="em-for-gaussian-mixture-models">
<h3><span class="section-number">11.7.3. </span>EM for Gaussian mixture models<a class="headerlink" href="#em-for-gaussian-mixture-models" title="Permalink to this heading">#</a></h3>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="more-prob.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">10. </span>More probability theory</p>
      </div>
    </a>
    <a class="right-next"
       href="stats-estimators.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12. </span>Statistics and estimators</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-examples">11.1. First examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#head-to-tail-nodes">11.1.1. Head-to-tail nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tail-to-tail-nodes">11.1.2. Tail-to-tail nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#head-to-head-nodes">11.1.3. Head-to-head nodes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dags-and-pgms">11.2. DAGs and PGMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-and-d-separation">11.3. Independence and <span class="math notranslate nohighlight">\(d\)</span>-separation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-examples">11.4. More examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">11.4.1. Linear regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">11.4.2. Logistic regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-models">11.4.3. Markov models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-mixture-models">11.4.4. Gaussian mixture models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-based-optimization">11.5. Gradient-based optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-gradient-descent">11.5.1. Vanilla gradient descent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd">11.5.2. Stochastic gradient descent (SGD)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle">11.6. Maximum likelihood estimation (MLE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-basics">11.6.1. The basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-linear-regression">11.6.2. MLE for linear regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-logistic-regression">11.6.3. MLE for logistic regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-markov-models">11.6.4. MLE for Markov models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization-em">11.7. Expectation maximization (EM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-em">11.7.1. Vanilla EM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-em-mcem">11.7.2. Monte Carlo EM (MCEM)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#em-for-gaussian-mixture-models">11.7.3. EM for Gaussian mixture models</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By John Myers
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>