
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>15. Statistics and general parameter estimation &#8212; Mathematical Statistics with a View Toward Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "\\operatorname*{argmax}", "argmin": "\\operatorname*{argmin}", "MSE": "\\operatorname*{MSE}", "MAE": "\\operatorname*{MAE}", "Ber": "\\mathcal{B}er", "Beta": "\\mathcal{B}eta", "Bin": "\\mathcal{B}in", "def": "\\stackrel{\\text{def}}{=}", "balpha": "\\boldsymbol\\alpha", "bbeta": "\\boldsymbol\\beta", "bdelta": "\\boldsymbol\\delta", "bmu": "\\boldsymbol\\mu", "bfeta": "\\boldsymbol\\eta", "btheta": "\\boldsymbol\\theta", "bpi": "\\boldsymbol\\pi", "bTheta": "\\boldsymbol\\Theta", "bSigma": "\\boldsymbol\\Sigma", "dev": "\\varepsilon", "bbr": "\\mathbb{R}", "ba": "\\mathbf{a}", "bb": "\\mathbf{b}", "bc": "\\mathbf{c}", "bd": "\\mathbf{d}", "be": "\\mathbf{e}", "bf": "\\mathbf{f}", "bg": "\\mathbf{g}", "bp": "\\mathbf{p}", "br": "\\mathbf{r}", "bs": "\\mathbf{s}", "bu": "\\mathbf{u}", "bv": "\\mathbf{v}", "bw": "\\mathbf{w}", "bx": "\\mathbf{x}", "by": "\\mathbf{y}", "bz": "\\mathbf{z}", "bA": "\\mathbf{A}", "bB": "\\mathbf{B}", "bE": "\\mathbf{E}", "bF": "\\mathbf{F}", "bD": "\\mathbf{D}", "bH": "\\mathbf{H}", "bI": "\\mathbf{I}", "bK": "\\mathbf{K}", "bS": "\\mathbf{S}", "bP": "\\mathbf{P}", "bQ": "\\mathbf{Q}", "bW": "\\mathbf{W}", "bX": "\\mathbf{X}", "bY": "\\mathbf{Y}", "bZ": "\\mathbf{Z}", "calJ": "\\mathcal{J}", "calH": "\\mathcal{H}", "calI": "\\mathcal{I}", "calL": "\\mathcal{L}", "calN": "\\mathcal{N}", "calP": "\\mathcal{P}", "calS": "\\mathcal{S}", "Jac": "\\operatorname{Jac}", "thetaMLE": "\\widehat{\\theta}_{\\text{MLE}}", "bthetaMLE": "\\widehat{\\btheta}_{\\text{MLE}}", "thetaMAP": "\\widehat{\\theta}_{\\text{MAP}}", "bthetaMAP": "\\widehat{\\btheta}_{\\text{MAP}}", "hattheta": "\\widehat{\\theta}", "hatbtheta": "\\widehat{\\btheta}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/15-stats-estimators';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="16. Confidence intervals" href="16-CIs-hyp-tests.html" />
    <link rel="prev" title="14. Large sample theory" href="14-large-sample.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Mathematical Statistics with a View Toward Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-preview.html">1. Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-prob-spaces.html">2. Probability spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-rules-of-prob.html">3. Rules of probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-random-variables.html">4. Random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-examples-of-rvs.html">5. Examples of random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-theory-to-practice.html">6. Connecting theory to practice: a first look at model building</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-random-vectors.html">7. Random vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-more-prob.html">8. More probability theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-halfway.html">9. The halfway point: pivoting toward models and data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-info-theory.html">10. Information theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-optim.html">11. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-models.html">12. Probabilistic graphical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-learning.html">13. Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-large-sample.html">14. Large sample theory</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">15. Statistics and general parameter estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-CIs-hyp-tests.html">16. Confidence intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-lin-reg.html">17. More on linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="bib.html">18. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jmyers7/stats-book-materials" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/15-stats-estimators.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Statistics and general parameter estimation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics">15.1. Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#general-parametric-models">15.2. General parametric models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimators">15.3. Parameter estimators</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><strong>THIS CHAPTER IS CURRENTLY UNDER CONSTRUCTION!!!</strong></p>
<section class="tex2jax_ignore mathjax_ignore" id="statistics-and-general-parameter-estimation">
<span id="stats-estimators"></span><h1><span class="section-number">15. </span>Statistics and general parameter estimation<a class="headerlink" href="#statistics-and-general-parameter-estimation" title="Link to this heading">#</a></h1>
<section id="statistics">
<h2><span class="section-number">15.1. </span>Statistics<a class="headerlink" href="#statistics" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="statistic-def">
<p class="admonition-title"><span class="caption-number">Definition 15.1 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bX\)</span> be a <span class="math notranslate nohighlight">\(k\)</span>-dimensional random vector. A <em>(<span class="math notranslate nohighlight">\(d\)</span>-dimensional) statistic</em> is a random vector of the form</p>
<div class="math notranslate nohighlight">
\[
T = r(\bX),
\]</div>
<p>where <span class="math notranslate nohighlight">\(r:\bbr^k \to \bbr^d\)</span> is a vector-valued function. An observed value <span class="math notranslate nohighlight">\(t\)</span> of <span class="math notranslate nohighlight">\(T\)</span> is called an <em>observed statistic</em> or <em>empirical statistic</em>.</p>
</section>
</div><p>If we conceptualize the random vector <span class="math notranslate nohighlight">\(\bX\)</span> as (theoretical) data, then a statistic is simply a function of the data. Crucially important examples of statistics include those defined as follows:</p>
<div class="proof definition admonition" id="sample-mean-var-def">
<p class="admonition-title"><span class="caption-number">Definition 15.2 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bX = (X_1,\ldots,X_m)\)</span> be an <span class="math notranslate nohighlight">\(m\)</span>-dimensional random vector. The <em>sample mean</em> is defined to be the statistic</p>
<div class="math notranslate nohighlight">
\[
\overline{X} \def \frac{1}{m}(X_1+\cdots+X_m),
\]</div>
<p>while the <em>sample variance</em> is defined to be the statistic</p>
<div class="math notranslate nohighlight">
\[
S^2 \def \frac{1}{m-1} \sum_{i=1}^m(X_i - \overline{X})^2.
\]</div>
<p>The corresponding empirical statistics are the <em>empirical mean</em> and <em>empirical variance</em> defined as</p>
<div class="math notranslate nohighlight">
\[
\overline{x} \def \frac{1}{m}(x_1+\cdots+x_m) \quad \text{and} \quad s^2 = \frac{1}{m-1} \sum_{i=1}^m(x_i - \overline{x})^2.
\]</div>
</section>
</div><p>Very often, the component random variables <span class="math notranslate nohighlight">\(X_1,\ldots,X_m\)</span> of the random vector <span class="math notranslate nohighlight">\(\bX\)</span> in the definition are assumed to form a random sample, i.e., an IID sequence of random variables. The dimension <span class="math notranslate nohighlight">\(m\)</span> is then referred to as the <em>sample size</em>. In principle, then, the sample size <span class="math notranslate nohighlight">\(m\)</span> can be <em>any</em> positive integer, and so it is often convenient to write <span class="math notranslate nohighlight">\(\overline{X}_m\)</span> for the sample mean, explicitly displaying the sample size. This gives us an entire <em>infinite sequence</em> of sample means:</p>
<div class="math notranslate nohighlight" id="equation-seq-means-eqn">
<span class="eqno">(15.1)<a class="headerlink" href="#equation-seq-means-eqn" title="Link to this equation">#</a></span>\[
\overline{X}_1,\overline{X}_2,\ldots,\overline{X}_m, \ldots.
\]</div>
<p>Since statistics are random vectors, they have their own probability distributions. These are given special names:</p>
<div class="proof definition admonition" id="samp-dist-def">
<p class="admonition-title"><span class="caption-number">Definition 15.3 </span></p>
<section class="definition-content" id="proof-content">
<p>The probability distribution of a statistic <span class="math notranslate nohighlight">\(T\)</span> is called the <em>sampling distribution</em> of <span class="math notranslate nohighlight">\(T\)</span>.</p>
</section>
</div><p>The sampling distributions for sample means <span class="math notranslate nohighlight">\(\overline{X}_m\)</span> are particularly important, and one of the main goals of <a class="reference internal" href="14-large-sample.html#asymptotic"><span class="std std-numref">Chapter 14</span></a> is to study the limiting behavior (or <em>asymptotic behavior</em>) of the sampling distributions in the sequence <a class="reference internal" href="#equation-seq-means-eqn">(15.1)</a> as <span class="math notranslate nohighlight">\(m\to \infty\)</span>.</p>
<p>In general, however, computing the sampling distributions is difficult. But if we actually have <em>observed</em> data <span class="math notranslate nohighlight">\(x_1,x_2,\ldots,x_m\)</span>, then (as you will explore in the programming assignment) there is a resampling method known as <em>bootstrapping</em> that yields  approximations to sampling distributions. An example is given by the histogram (with KDE) on the right-hand side of the following figure, where a histogram (with KDE) of the empirical distribution of an observed dataset is given on the left-hand side:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline.backend_inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span> <span class="k">as</span> <span class="nn">clr</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../aux-files/custom_style_light.mplstyle&#39;</span><span class="p">)</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">blue</span> <span class="o">=</span> <span class="s1">&#39;#486AFB&#39;</span>
<span class="n">magenta</span> <span class="o">=</span> <span class="s1">&#39;#FD46FC&#39;</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">resample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">random_sample</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">replicate_means</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_resamples</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_resamples</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">random_sample</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">resample_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">replicate_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">random_sample</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">replicate_means</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;density&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;observed data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;density&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;bootstrap sampling distribution of sample mean&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<img alt="../_images/c3b413cb7af81f374c19b1c86ca8162cc6e7b28bf8e54551e3892ddb2b0a1217.svg" src="../_images/c3b413cb7af81f374c19b1c86ca8162cc6e7b28bf8e54551e3892ddb2b0a1217.svg" /></figure>
</div>
</div>
<p>Observe that the sampling distribution on the right-hand side appears to be well approximated by a normal distribution. This is actually a manifestation of the asymptotic behavior of sample means that we alluded to above; indeed, as we will see in <a class="reference internal" href="14-large-sample.html#asymptotic"><span class="std std-numref">Chapter 14</span></a>, the Central Limit Theorem tells us that the sequence <a class="reference internal" href="#equation-seq-means-eqn">(15.1)</a> of sample means converges (in distribution) to a normal distribution as <span class="math notranslate nohighlight">\(m\to \infty\)</span>, provided that the random variables are IID. This is true even though the observed data are definitely <em>not</em> normally distributed. Moreover, the mean of the sampling distribution is approximately <span class="math notranslate nohighlight">\(4.924\)</span>, while the mean of the observed data is approximately <span class="math notranslate nohighlight">\(4.928\)</span>. The fact that these means are nearly equal is a consequence of another theorem in <a class="reference internal" href="14-large-sample.html#asymptotic"><span class="std std-numref">Chapter 14</span></a> called the Law of Large Numbers. These asymptotic results provide the foundation for the large-sample <em>confidence intervals</em> that we will construct in <a class="reference internal" href="16-CIs-hyp-tests.html#cis"><span class="std std-numref">Chapter 16</span></a>.</p>
<p>Let’s consider the sample mean a little closer:</p>
<div class="proof theorem admonition" id="prop-sample-mean-thm">
<p class="admonition-title"><span class="caption-number">Theorem 15.1 </span> (Properties of the sample mean)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,\ldots,X_m\)</span> be an IID random sample from a distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<ol class="arabic simple">
<li><p>The expectation of the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>The variance of the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is <span class="math notranslate nohighlight">\(\sigma^2/m\)</span>, and hence its standard deviation is <span class="math notranslate nohighlight">\(\sigma/\sqrt{m}\)</span>.</p></li>
<li><p>If the <span class="math notranslate nohighlight">\(X_i\)</span>’s are normally distributed, then so too is the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span>.</p></li>
</ol>
</section>
</div><p>You will prove this theorem as</p>
</section>
<section id="general-parametric-models">
<h2><span class="section-number">15.2. </span>General parametric models<a class="headerlink" href="#general-parametric-models" title="Link to this heading">#</a></h2>
<p>Abstracting away all the intricate particularities of the fully-observed probabilistic graphical models in <a class="reference internal" href="12-models.html#prob-models"><span class="std std-numref">Chapter 12</span></a> reveals that they all are examples of the following type of general structure:</p>
<div class="proof definition admonition" id="gen-para-model-def">
<p class="admonition-title"><span class="caption-number">Definition 15.4 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bX\)</span> be a <span class="math notranslate nohighlight">\(k\)</span>-dimensional random vector and let <span class="math notranslate nohighlight">\(\Omega\)</span> be a (nonempty) subset of a Euclidean space <span class="math notranslate nohighlight">\(\bbr^d\)</span>. A <em>parametric probabilistic model</em> (or simply a <em>parametric model</em>) for <span class="math notranslate nohighlight">\(\bX\)</span> is a specification of a dependence of the probability distribution of <span class="math notranslate nohighlight">\(\bX\)</span> on values <span class="math notranslate nohighlight">\(\btheta \in \Omega\)</span>. In other words, a <em>parametric model</em> is simply a family</p>
<div class="math notranslate nohighlight" id="equation-para-model-eqn">
<span class="eqno">(15.2)<a class="headerlink" href="#equation-para-model-eqn" title="Link to this equation">#</a></span>\[
\calP_0 = \{P_\btheta : \btheta \in \Omega\}
\]</div>
<p>of probability distributions on <span class="math notranslate nohighlight">\(\bbr^k\)</span> such that <span class="math notranslate nohighlight">\(\bX \sim P_\btheta\)</span>. In this context, the set <span class="math notranslate nohighlight">\(\Omega\)</span> is called the <em>parameter space</em>, each <span class="math notranslate nohighlight">\(\btheta \in \Omega\)</span> is called a (<span class="math notranslate nohighlight">\(d\)</span>-dimensional) <em>parameter</em>, and the vector <span class="math notranslate nohighlight">\(\bX\)</span> is called the <em>data</em>.</p>
</section>
</div><p>Very often, we shall specify a parametric model <a class="reference internal" href="#equation-para-model-eqn">(15.2)</a> by listing the density functions of the probability measures <span class="math notranslate nohighlight">\(P_\btheta\)</span>, provided that these exist. In other words, we will write</p>
<div class="math notranslate nohighlight">
\[
\calP_0 = \{ p(\bx; \btheta): \btheta \in \Omega\}.
\]</div>
<p>The simplest examples of parametric models are the univariate models introduced and studied in <a class="reference internal" href="05-examples-of-rvs.html#examples"><span class="std std-numref">Chapter 5</span></a>. Indeed, if we have <span class="math notranslate nohighlight">\(X \sim \Ber(\theta)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_0 = \{ p(x;\theta) : \theta \in [0,1] \}, \quad p(x;\theta) = \theta^x (1-\theta)^{1-x}, \ x\in \{0,1\},
\]</div>
<p>is a parametric model with <span class="math notranslate nohighlight">\(1\)</span>-dimensional parameter space <span class="math notranslate nohighlight">\(\Omega = [0,1]\)</span>. Similarly, if we have <span class="math notranslate nohighlight">\(X\sim \calN(\mu,\sigma^2)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_0 = \{ p(x;\btheta) : \btheta = (\mu,\sigma^2) \in \bbr \times (0,\infty) \}, \quad p(x;\btheta) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp \left[ -\frac{1}{2\sigma^2} (x-\mu)^2\right],
\]</div>
<p>is a parametric model with <span class="math notranslate nohighlight">\(2\)</span>-dimensional parameter space <span class="math notranslate nohighlight">\(\Omega = \bbr \times (0,\infty)\)</span>.</p>
<p>As we mentioned above, all the fully-observed probabilistic graphical models studied in <a class="reference internal" href="12-models.html#prob-models"><span class="std std-numref">Chapter 12</span></a> are examples of this general type of parametric model. For example, a linear regression model with <span class="math notranslate nohighlight">\(n\)</span>-dimensional predictor vector <span class="math notranslate nohighlight">\(\bX\)</span> and response variable <span class="math notranslate nohighlight">\(Y\)</span> defines a parametric model</p>
<div class="math notranslate nohighlight">
\[
\calP_0 = \{ p(\bx, y; \btheta) : \btheta = (\beta_0,\bbeta,\sigma^2) \in \bbr \times \bbr^n \times (0,\infty)\}
\]</div>
<p>with <span class="math notranslate nohighlight">\((n+2)\)</span>-dimensional parameter space <span class="math notranslate nohighlight">\(\Omega = \bbr \times \bbr^n \times (0,\infty)\)</span> and where</p>
<div class="math notranslate nohighlight">
\[
p(\bx, y; \btheta) = p(y \mid \bx; \btheta) p(\bx) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp \left[ -\frac{1}{2\sigma^2} (y-\beta_0 - \bx^\intercal \bbeta)^2\right] p(\bx).
\]</div>
<p>In this latter example, notice that the <span class="math notranslate nohighlight">\((n+1)\)</span>-dimensional random vector <span class="math notranslate nohighlight">\((\bX,Y)\)</span> plays the roll of the vector <span class="math notranslate nohighlight">\(\bX\)</span> in <a class="reference internal" href="#para-model-def">Definition 15.5</a> (so that <span class="math notranslate nohighlight">\(k=n+1\)</span>).</p>
<p>The “plated” versions of the fully-observed PGMs in <a class="reference internal" href="12-models.html#prob-models"><span class="std std-numref">Chapter 12</span></a> also define parametric models in the sense of <a class="reference internal" href="#para-model-def">Definition 15.5</a>. For example, a “plated” version of our linear regression model from above would define the parametric model</p>
<div class="math notranslate nohighlight">
\[
\calP_0 = \{ p(\bx_1,\ldots,\bx_m,y_1,\ldots,y_m; \btheta) : \btheta = (\beta_0,\bbeta,\sigma^2) \in \Omega\}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\Omega\)</span> is the same parameter space as above and where</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p(\bx_1,\ldots,\bx_m,y_1,\ldots,y_m; \btheta) &amp;= p(y_1,\ldots,y_m \mid \bx_1,\ldots,\bx_m) p(\bx_1,\ldots,\bx_m) \\
&amp;= \left\{\prod_{i=1}^m \frac{1}{\sqrt{2\pi \sigma^2}}\exp \left[ -\frac{1}{2\sigma^2} (y_i-\beta_0 - \bx_i^\intercal \bbeta)^2\right]\right\} p(\bx_1,\ldots,\bx_m).
\end{align*}\]</div>
<p>In this case, the <span class="math notranslate nohighlight">\((mn + m)\)</span>-dimensional random vector <span class="math notranslate nohighlight">\((\bX_1,\ldots,\bX_m,y_1,\ldots,y_m)\)</span> plays the roll of the vector <span class="math notranslate nohighlight">\(\bX\)</span> in <a class="reference internal" href="#para-model-def">Definition 15.5</a> (so that <span class="math notranslate nohighlight">\(k=mn+m\)</span>).</p>
</section>
<section id="parameter-estimators">
<h2><span class="section-number">15.3. </span>Parameter estimators<a class="headerlink" href="#parameter-estimators" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="para-model-def">
<p class="admonition-title"><span class="caption-number">Definition 15.5 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\calP_0\)</span> be a parametric model for a <span class="math notranslate nohighlight">\(k\)</span>-dimensional random vector <span class="math notranslate nohighlight">\(\bX\)</span> with <span class="math notranslate nohighlight">\(d\)</span>-dimensional parameter space <span class="math notranslate nohighlight">\(\Omega\)</span>. A <em>parameter estimator</em> (or simply an <em>estimator</em>) is a statistic</p>
<div class="math notranslate nohighlight">
\[
\hatbtheta = \delta(\bX),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\delta: \bbr^k \to \bbr^d\)</span> is a vector-valued function. An observed value of <span class="math notranslate nohighlight">\(\hatbtheta\)</span> is called a <em>point estimate</em>.</p>
</section>
</div><p>There will be much abuse of terminology and notation regarding parameter estimators; it seems wise, then, to formally issue the following:</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ol class="arabic simple">
<li><p>Following our previously established convention of representing random objects with capital letters, we <em>should</em> write a parameter estimator as <span class="math notranslate nohighlight">\(\widehat{\boldsymbol \Theta}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol\Theta\)</span> is a capital theta. However, this is notationally awkward, so we will not do this.</p></li>
<li><p>Though technically the parameter estimator is the random vector <span class="math notranslate nohighlight">\(\hatbtheta\)</span>, we will use the word <em>estimator</em> to also refer to the function <span class="math notranslate nohighlight">\(\delta\)</span>. Moreover, we will often use the notations <span class="math notranslate nohighlight">\(\hatbtheta\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span> interchangeably.</p></li>
<li><p>To complicate things even more, we will sometimes write <span class="math notranslate nohighlight">\(\hatbtheta\)</span> to refer to a point estimate.</p></li>
</ol>
</div>
<p>Thus, the single piece of notation <span class="math notranslate nohighlight">\(\hatbtheta\)</span> might stand for one of three things: Either the random vector <span class="math notranslate nohighlight">\(\delta(\bX)\)</span>, the function <span class="math notranslate nohighlight">\(\delta\)</span>, or an observed value of the random vector <span class="math notranslate nohighlight">\(\delta(\bX)\)</span>. You will need to rely on context to determine which of these three objects is meant when you encounter the symbol <span class="math notranslate nohighlight">\(\hatbtheta\)</span>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="14-large-sample.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">14. </span>Large sample theory</p>
      </div>
    </a>
    <a class="right-next"
       href="16-CIs-hyp-tests.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">16. </span>Confidence intervals</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics">15.1. Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#general-parametric-models">15.2. General parametric models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimators">15.3. Parameter estimators</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By John Myers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>