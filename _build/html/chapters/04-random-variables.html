

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>4. Random variables &#8212; Mathematical Statistics with a View Toward Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "\\operatorname*{argmax}", "argmin": "\\operatorname*{argmin}", "MSE": "\\operatorname*{MSE}", "MAE": "\\operatorname*{MAE}", "Ber": "\\mathcal{B}er", "Beta": "\\mathcal{B}eta", "Bin": "\\mathcal{B}in", "def": "\\stackrel{\\text{def}}{=}", "balpha": "\\boldsymbol\\alpha", "bbeta": "\\boldsymbol\\beta", "bdelta": "\\boldsymbol\\delta", "bmu": "\\boldsymbol\\mu", "bfeta": "\\boldsymbol\\eta", "btheta": "\\boldsymbol\\theta", "bpi": "\\boldsymbol\\pi", "bTheta": "\\boldsymbol\\Theta", "bSigma": "\\boldsymbol\\Sigma", "dev": "\\varepsilon", "bbr": "\\mathbb{R}", "ba": "\\mathbf{a}", "bb": "\\mathbf{b}", "bc": "\\mathbf{c}", "bd": "\\mathbf{d}", "be": "\\mathbf{e}", "bg": "\\mathbf{g}", "bp": "\\mathbf{p}", "bu": "\\mathbf{u}", "bv": "\\mathbf{v}", "bw": "\\mathbf{w}", "bx": "\\mathbf{x}", "by": "\\mathbf{y}", "bz": "\\mathbf{z}", "bA": "\\mathbf{A}", "bB": "\\mathbf{B}", "bE": "\\mathbf{E}", "bF": "\\mathbf{F}", "bD": "\\mathbf{D}", "bH": "\\mathbf{H}", "bI": "\\mathbf{I}", "bK": "\\mathbf{K}", "bS": "\\mathbf{S}", "bP": "\\mathbf{P}", "bQ": "\\mathbf{Q}", "bX": "\\mathbf{X}", "bY": "\\mathbf{Y}", "bZ": "\\mathbf{Z}", "calJ": "\\mathcal{J}", "calH": "\\mathcal{H}", "calN": "\\mathcal{N}", "calP": "\\mathcal{P}", "Jac": "\\operatorname{Jac}", "thetaMLE": "\\widehat{\\theta}_{\\text{MLE}}", "bthetaMLE": "\\widehat{\\btheta}_{\\text{MLE}}", "thetaMAP": "\\widehat{\\theta}_{\\text{MAP}}", "bthetaMAP": "\\widehat{\\btheta}_{\\text{MAP}}", "hattheta": "\\widehat{\\theta}", "hatbtheta": "\\widehat{\\btheta}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/04-random-variables';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Examples of random variables" href="05-examples-of-rvs.html" />
    <link rel="prev" title="3. Rules of probability" href="03-rules-of-prob.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Mathematical Statistics with a View Toward Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-preview.html">1. Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-prob-spaces.html">2. Probability spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-rules-of-prob.html">3. Rules of probability</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">4. Random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-examples-of-rvs.html">5. Examples of random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-theory-to-practice.html">6. Connecting theory to practice: a first look at model building</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-random-vectors.html">7. Random vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-more-prob.html">8. More probability theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-halfway.html">9. The halfway point: pivoting toward models and data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-info-theory.html">10. Information theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-optim.html">11. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-models.html">12. Probabilistic graphical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-learning.html">13. Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-stats-estimators.html">14. Statistics and general parameter estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="15-asymptotic.html">15. Large sample theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-CIs.html">16. Confidence intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-hyp-test.html">17. Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="18-lin-reg.html">18. Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="bib.html">19. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jmyers7/stats-book-materials" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/04-random-variables.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Random variables</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">4.1. Random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-measures-of-random-variables">4.2. Probability measures of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-and-continuous-random-variables">4.3. Discrete and continuous random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-and-quantile-functions">4.4. Distribution and quantile functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-values">4.5. Expected values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-algebra-of-random-variables">4.6. The algebra of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-of-random-variables">4.7. Functions of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations-of-functions-of-random-variables-and-the-lotus">4.8. Expectations of functions of random variables and the LotUS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linearity-of-expectation">4.9. Linearity of expectation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variances-and-standard-deviations">4.10. Variances and standard deviations</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="random-variables">
<span id="id1"></span><h1><span class="section-number">4. </span>Random variables<a class="headerlink" href="#random-variables" title="Permalink to this heading">#</a></h1>
<section id="id2">
<h2><span class="section-number">4.1. </span>Random variables<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>I do not think it is too much of a stretch to say that <em>random variables</em> are the objects that most concern practitioners who use probability and statistics in their work. In this section, I want to give a concrete introduction to these gadgets, saving their precise, mathematical definition for a little later.</p>
<p>As a first example, let’s think about the population that you and I are all members of: The current population <span class="math notranslate nohighlight">\(S\)</span> of the planet Earth. As members of this population, we all have different characteristics, qualities, or features that distinguish us from one another. For example, we all have:</p>
<ul class="simple">
<li><p>An age.</p></li>
<li><p>A country of legal residence.</p></li>
<li><p>An annual income (converted to some standard monetary system, like USD or euros).</p></li>
<li><p>A primary profession.</p></li>
<li><p><em>etc</em>.</p></li>
</ul>
<p>If you’re interested in business, advertising, and sales applications, then you might have a <em>different</em> population <span class="math notranslate nohighlight">\(S\)</span> in mind. For example, your population might be all past customers who have purchased your company’s product, and you might query the various features of this population in order to construct better future advertising campaigns. Can you think of some features of past customers that might be of interest?</p>
<p>Or, your population <span class="math notranslate nohighlight">\(S\)</span> might not even be a population of <em>people</em>; for example, you might work for a manufacturing company, and <span class="math notranslate nohighlight">\(S\)</span> could be the collection of all devices manufactured in the past year. Then, some features of this population might be:</p>
<ul class="simple">
<li><p>Date of manufacture of the device.</p></li>
<li><p>A binary ‘yes’ or ‘no’ depending on whether the device turned out to be defective within a certain time period.</p></li>
<li><p>Country of sale.</p></li>
<li><p><em>etc</em>.</p></li>
</ul>
<p>Hopefully you can see that this idea of <em>features</em> is very broad, and can be applied in many situations and cases.</p>
<p>All the features mentioned above are also called <em>variables</em>, because they <em>vary</em> across members of the population. For example, we have the ‘age’ variable defined on the population of planet Earth, as well as the ‘primary profession’ variable, and so on. Some of these variables take on numerical values, while others do not; for example, ‘age’ is a numerical variable, while ‘primary profession’ is not. The types of variables that will most interest us (for now) are the numerical ones.</p>
<p>Now, so far nothing about probability has been mentioned. But when the population under consideration is a probability space, it is traditional to refer to variables (or features) of the population as <em>random variables</em>, the word ‘random’ simply reflecting that there is now a probability measure in the mix. The word ‘random’ is perhaps not the best, because for many of us ‘random’ already has such a strong meaning from everyday language. For this reason, sometimes <em>random variables</em> are called <em>stochastic variables</em>, so that we’re not misled in to thinking that there is something “random” about them (there isn’t).</p>
<p>Though the term <em>random variable</em> is common in statistics, the term <em>feature</em> is much more common in the machine learning community. Often, the plain term <em>variable</em> is also used. I will bounce back and forth between these pieces of terminology without explicit mention. But no matter what you call them, they will be <em>very</em> important throughout the rest of this course. In fact, as you will see, the probability spaces that we’ve worked so hard to understand—and which serve as the domains of our random variables—will essentially recede into the background, and the random variables themselves will become the things that we talk about on a daily basis.</p>
<p>Alright, good. We feel like we have an intuitive, concrete understanding of what <em>random variables</em> (or <em>features</em>, or <em>variables</em>) are. They are simply numerical characteristics or qualities of samples points in a probability space. But how might we encode this notion in mathematics? How might we take our intuitive definition of <em>random variable</em> and turn it into a precise mathematical definition?</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Apparently, there are only 32 of us—I counted the stick people!—and we all live on a rectangular planet Earth.</p>
</aside>
<p>Let’s return to the sample space <span class="math notranslate nohighlight">\(S\)</span> representing the population of the planet Earth:</p>
<a class="reference internal image-reference" href="../_images/population.svg"><img alt="../_images/population.svg" class="align-center" src="../_images/population.svg" width="45%" /></a>
<p> </p>
<p>Let’s talk about the ‘annual income’ variable (or feature). We might conceptualize it as a “machine” into which we feed individuals from the population, and then the machine spits out their annual income:</p>
<a class="reference internal image-reference" href="../_images/income.svg"><img alt="../_images/income.svg" class="align-center" src="../_images/income.svg" width="90%" /></a>
<p> </p>
<p>I’ve given this machine the name <span class="math notranslate nohighlight">\(I\)</span>, to stand for <strong>I</strong>ncome. We might also be interested in the ‘age’ variable; this leads us to consider another “machine,” this time named <span class="math notranslate nohighlight">\(A\)</span>:</p>
<a class="reference internal image-reference" href="../_images/age.svg"><img alt="../_images/age.svg" class="align-center" src="../_images/age.svg" width="90%" /></a>
<p> </p>
<p>The obsession that mathematicians have with “machines” is because they are concrete and easily understandable metaphors for the more formal notion of a <em>mathematical function</em>. Above, the “machines” <span class="math notranslate nohighlight">\(I\)</span> and <span class="math notranslate nohighlight">\(A\)</span> are simply objects that have inputs and outputs—indeed, both have inputs consisting of people, and the outputs are numbers. But this is <em>exactly</em> what a formal <em>mathematical function</em> is—it’s an object that has inputs and outputs! So, our “machines” above are really none other than <em>functions</em>, in the precise, mathematical sense.</p>
<p>To drive this point home, we might even use functional notation:</p>
<a class="reference internal image-reference" href="../_images/funcnotation.svg"><img alt="../_images/funcnotation.svg" class="align-center" src="../_images/funcnotation.svg" width="90%" /></a>
<p> </p>
<p>This way of writing things is modelled after the familiar functional notation used in other parts of mathematics:</p>
<a class="reference internal image-reference" href="../_images/funcnotation2.svg"><img alt="../_images/funcnotation2.svg" class="align-center" src="../_images/funcnotation2.svg" width="35%" /></a>
<p> </p>
<p>Our functions <span class="math notranslate nohighlight">\(I\)</span> and <span class="math notranslate nohighlight">\(A\)</span> may both be written as</p>
<div class="math notranslate nohighlight">
\[I:S \to \mathbb{R} \quad \text{and} \quad A: S \to \mathbb{R}.\]</div>
<p>This means that the domain of both <span class="math notranslate nohighlight">\(I\)</span> and <span class="math notranslate nohighlight">\(A\)</span> is the population <span class="math notranslate nohighlight">\(S\)</span>, while the outputs lie in the set <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> of real numbers.</p>
<p>So, does this mean that a <em>random variable</em> is secretly just a function? Yup! Here’s the definition:</p>
<div class="proof definition admonition" id="random-var-def">
<p class="admonition-title"><span class="caption-number">Definition 4.1 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(S\)</span> be a probability space. A <em>random variable</em> on <span class="math notranslate nohighlight">\(S\)</span> is a function <span class="math notranslate nohighlight">\(X:S \to \mathbb{R}\)</span>.</p>
</section>
</div><aside class="margin sidebar">
<p class="sidebar-title">Looking beyond…</p>
<p>Technically, not <em>every</em> function on a sample space qualifies as a random variable. As you would learn if you took a (<em>really</em>) advanced course in theoretical probability, random variables must have the additional property of being <a href="https://en.wikipedia.org/wiki/Measurable_function"><em>measurable</em></a>. But we won’t worry about this. At all. So you can forget I ever said anything.</p>
</aside>
<p>Therefore, a random variable on a sample space is nothing but a function that takes sample points as inputs, and spits out real numbers. That’s it!</p>
<p>Before we do some practice problems with random variables, let me add a few quick remarks:</p>
<ul>
<li><p>It is traditional in probability theory to use capital letters toward the end of the alphabet to name generic random variables, like <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>, instead of the more familiar lower case letters like <span class="math notranslate nohighlight">\(f\)</span>, <span class="math notranslate nohighlight">\(g\)</span>, and <span class="math notranslate nohighlight">\(h\)</span>. <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p>If a capital letter is used to represent a random variable itself, then the lowercase version of the same letter is often used to represent the generic <em>output</em> of a random variable. So, the functional notation template <span class="math notranslate nohighlight">\(f(x)=y\)</span> that you are familiar with from calculus becomes</p>
<div class="math notranslate nohighlight">
\[X(s) = x \quad \text{or} \quad Y(s) = y \quad \text{or} \quad Z(s) = z\]</div>
<p>in probability theory.</p>
</li>
<li><p>With all this being said, this ‘capital letter <span class="math notranslate nohighlight">\(=\)</span> random variable’ convention is <em>not</em> always strictly followed, especially if you read other textbooks, research papers, <em>etc</em>. Frankly, struggling through an author’s choice for statistical and probabilistic notation can sometimes be quite a nightmare.</p></li>
</ul>
<p>Now:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Let’s get some practice with random variables! Do problems 1-4 on the worksheet.</p>
</div>
</section>
<section id="probability-measures-of-random-variables">
<span id="prob-measure-rv"></span><h2><span class="section-number">4.2. </span>Probability measures of random variables<a class="headerlink" href="#probability-measures-of-random-variables" title="Permalink to this heading">#</a></h2>
<p>We know that a random variable on a probability space <span class="math notranslate nohighlight">\(S\)</span> is simply a real-valued function</p>
<div class="math notranslate nohighlight">
\[X:S \to \mathbb{R}.\]</div>
<p>Since <span class="math notranslate nohighlight">\(S\)</span> is a probability space, it comes equipped with a probability measure <span class="math notranslate nohighlight">\(P\)</span>, an object which measures the probabilities of events <span class="math notranslate nohighlight">\(A \subset S\)</span>. However, the random variable <span class="math notranslate nohighlight">\(X\)</span> “transports” the probability measure <span class="math notranslate nohighlight">\(P\)</span> to a second probability measure that I will denote <span class="math notranslate nohighlight">\(P_X\)</span> (since it depends on <span class="math notranslate nohighlight">\(Y\)</span>) which measures probabilities of events <span class="math notranslate nohighlight">\(A\subset \mathbb{R}\)</span>. Here’s a figure to help you remember <em>where</em> each of these probability measures live:</p>
<a class="reference internal image-reference" href="../_images/pushforward.svg"><img alt="../_images/pushforward.svg" class="align-center" src="../_images/pushforward.svg" width="70%" /></a>
<p> </p>
<p>It is best to introduce these concepts by way of example. So, let’s return to our example of the ‘annual income’ variable <span class="math notranslate nohighlight">\(I\)</span> from the previous section. But because I want you to get used to seeing <span class="math notranslate nohighlight">\(X\)</span> for the name of a random variable, let’s rename <span class="math notranslate nohighlight">\(I\)</span> to <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="math notranslate nohighlight">
\[I:S \to \mathbb{R} \quad \xrightarrow{\text{rename}} \quad X:S \to \mathbb{R}.\]</div>
<p>And remember, the sample space <span class="math notranslate nohighlight">\(S\)</span> is the current population of the planet Earth.</p>
<p>Now, for (extreme!) simplicity, let’s suppose that there are only four possible annual incomes in the entire population:</p>
<div class="math notranslate nohighlight">
\[\text{range of $X$} = \{35, 40, 45, 50\}.\]</div>
<p>The units are thousands of US dollars, so, for example,</p>
<div class="math notranslate nohighlight">
\[X(\text{John}) = 35\]</div>
<p>means that my annual income (Hi, I’m John) is 35,000 USD. We may group together all individuals in the sample space <span class="math notranslate nohighlight">\(S\)</span> based on their annual incomes:</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>By the way, if you remember the definition of a <em>partition</em> from an earlier chapter, what we have done is partition the sample space <span class="math notranslate nohighlight">\(S\)</span> based on the values of the random variable <span class="math notranslate nohighlight">\(Y\)</span>.</p>
</aside>
<a class="reference internal image-reference" href="../_images/discretedist0.svg"><img alt="../_images/discretedist0.svg" class="align-center" src="../_images/discretedist0.svg" width="40%" /></a>
<p> </p>
<p>I tend to view functions like <span class="math notranslate nohighlight">\(X\)</span> as “active” transformations, so I would picture the action of <span class="math notranslate nohighlight">\(X\)</span> as follows:</p>
<a class="reference internal image-reference" href="../_images/discretedist1.svg"><img alt="../_images/discretedist1.svg" class="align-center" src="../_images/discretedist1.svg" width="90%" /></a>
<p> </p>
<p>Notice that the variable <span class="math notranslate nohighlight">\(X\)</span>, as a function, is carrying certain portions of the sample space to certain values along <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, which I am picturing as a number line.</p>
<p>Let’s now bring in the probability measures. Let’s suppose for the sake of argument that the size of our sample space <span class="math notranslate nohighlight">\(S\)</span> (i.e., the population) is only 32 individuals, and that the probability measure <span class="math notranslate nohighlight">\(P\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is uniform. Thus, the probability of choosing any <em>one</em> person from <span class="math notranslate nohighlight">\(S\)</span> is:</p>
<div class="math notranslate nohighlight">
\[P(\{\text{a single person}\}) = \frac{1}{32}.\]</div>
<p>If you count all the little stick people, you will find:</p>
<ul class="simple">
<li><p>There are 7 people with annual income 35.</p></li>
<li><p>There are 8 people with annual income 40.</p></li>
<li><p>There are 12 people with annual income 45.</p></li>
<li><p>There are 5 people with annual income 50.</p></li>
</ul>
<p>Therefore, we compute:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
P(\{\text{people with annual income 35}\}) &amp;= 7/32 \approx 0.22, \\
P(\{\text{people with annual income 40}\}) &amp;= 8/32 = 0.25, \\
P(\{\text{people with annual income 45}\}) &amp;= 12/32 \approx 0.38, \\
P(\{\text{people with annual income 50}\}) &amp;= 5/32 \approx 0.16.
\end{align*}\]</div>
<p>Now, remember that in addition to the probability measure <span class="math notranslate nohighlight">\(P\)</span> on <span class="math notranslate nohighlight">\(S\)</span>, there is supposed to be a <em>second</em> probability measure <span class="math notranslate nohighlight">\(P_X\)</span> on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. It turns out, however, that these previous four probabilities <em>are</em> the probabilities that come from <span class="math notranslate nohighlight">\(P_X\)</span>, by definition! Indeed, we <em>define</em> the probability measure <span class="math notranslate nohighlight">\(P_X\)</span> on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> by setting</p>
<div class="math notranslate nohighlight" id="equation-inv-01-eqn">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-inv-01-eqn" title="Permalink to this equation">#</a></span>\[P_X(\{x\}) = P(\{\text{people with annual income $x$}\})\]</div>
<p>for each <span class="math notranslate nohighlight">\(x\in \mathbb{R}\)</span>, so that we may rewrite the above equations using <span class="math notranslate nohighlight">\(P_X\)</span> as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
P_X(\{35\}) &amp;= 7/32 \approx 0.22, \\
P_X(\{40\}) &amp;= 8/32 = 0.25, \\
P_X(\{45\}) &amp;= 12/32 \approx 0.38, \\
P_X(\{50\}) &amp;= 5/32 \approx 0.16.
\end{align*}\]</div>
<p>The equation <a class="reference internal" href="#equation-inv-01-eqn">(4.1)</a> is the fundamental bridge that relates the two probability measures <span class="math notranslate nohighlight">\(P\)</span> (on <span class="math notranslate nohighlight">\(S\)</span>) and <span class="math notranslate nohighlight">\(P_X\)</span> (on <span class="math notranslate nohighlight">\(\mathbb{R})\)</span>, so make sure that you understand it! (It will reappear below in the abstract definitions.)</p>
<p>The probability measure <span class="math notranslate nohighlight">\(P\)</span> lives on the original probability space <span class="math notranslate nohighlight">\(S\)</span>, so we can’t really <em>visualize</em> it since <span class="math notranslate nohighlight">\(S\)</span> doesn’t have a nice linear structure like <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. However, the probability measure <span class="math notranslate nohighlight">\(P_X\)</span> lives on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, so we <em>can</em> visualize <em>it</em> using a probability histogram:</p>
<a class="reference internal image-reference" href="../_images/discretedist.svg"><img alt="../_images/discretedist.svg" class="align-center" src="../_images/discretedist.svg" width="90%" /></a>
<p> </p>
<p>The heights of the bars above each numerical value in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> represent the probabilities measured by <span class="math notranslate nohighlight">\(P_X\)</span>.</p>
<p>Ok. Having worked our way through a concrete example, we are now ready for the abstract definitions.</p>
<div class="proof definition admonition" id="prob-measure-X-defn">
<p class="admonition-title"><span class="caption-number">Definition 4.2 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X:S\to \mathbb{R}\)</span> be a random variable on a probability space <span class="math notranslate nohighlight">\(S\)</span> with probability measure <span class="math notranslate nohighlight">\(P\)</span>. We define the <em>probability measure of <span class="math notranslate nohighlight">\(X\)</span></em>, denoted <span class="math notranslate nohighlight">\(P_X\)</span>, via the formula</p>
<div class="math notranslate nohighlight" id="equation-inv2-eqn">
<span class="eqno">(4.2)<a class="headerlink" href="#equation-inv2-eqn" title="Permalink to this equation">#</a></span>\[P_X(A) = P \big( \{ s\in S : X(s) \in A\} \big),\]</div>
<p>for all events <span class="math notranslate nohighlight">\(A\subset \mathbb{R}\)</span>.</p>
</section>
</div><p>For a given event <span class="math notranslate nohighlight">\(A\subset \mathbb{R}\)</span>, notice that the set</p>
<div class="math notranslate nohighlight">
\[
\{s \in S : X(s) \in A)\} \subset S
\]</div>
<p>inside the probability measure on the right-hand side of <a class="reference internal" href="#equation-inv2-eqn">(4.2)</a> consists exactly of those sample points <span class="math notranslate nohighlight">\(s\in S\)</span> that land in <span class="math notranslate nohighlight">\(A\)</span> under the action of the random variable <span class="math notranslate nohighlight">\(X\)</span>; I would visualize this as:</p>
<a class="reference internal image-reference" href="../_images/pushforward-2.svg"><img alt="../_images/pushforward-2.svg" class="align-center" src="../_images/pushforward-2.svg" width="70%" /></a>
<p> </p>
<div class="admonition-alternate-notation admonition">
<p class="admonition-title">Alternate notation</p>
<p>In the <em>mathematical</em> theory of probability, the notation <span class="math notranslate nohighlight">\(P_X\)</span> is very common for the probability measure induced by <span class="math notranslate nohighlight">\(X\)</span>. However, in elementary statistics it is much more common to write</p>
<div class="math notranslate nohighlight">
\[P(X\in A) \quad \text{in place of} \quad P_X(A),\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[P(X=x) \quad \text{in place of} \quad P_X\big(\{x\} \big),\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[P(a\leq X \leq b) \quad \text{in place of} \quad P_X\big([a,b] \big).\]</div>
<p>In deference to tradition, I will use these alternate notations almost always.</p>
<p>However, I want to point out the following:</p>
<ul class="simple">
<li><p>Do notice that these alternate notations are actually <em>misuses</em> of notation, since the expressions “<span class="math notranslate nohighlight">\(X\in A\)</span>”, “<span class="math notranslate nohighlight">\(X=x\)</span>”, and “<span class="math notranslate nohighlight">\(a\leq X \leq b\)</span>” are complete nonsense. Indeed, remember that <span class="math notranslate nohighlight">\(X\)</span> is a function, while <span class="math notranslate nohighlight">\(x\)</span> is a number, so there is <strong>no way</strong> that <span class="math notranslate nohighlight">\(X\)</span> could be equal to <span class="math notranslate nohighlight">\(x\)</span>, since they are <em>different</em> types of objects!</p></li>
<li><p>In the alternate notation, notice that the single letter <span class="math notranslate nohighlight">\(P\)</span> is used to denote <em>both</em> the original probability measure on <span class="math notranslate nohighlight">\(S\)</span> <em>and</em> the second probability measure of <span class="math notranslate nohighlight">\(X\)</span> on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. This might make you think that there is only <em>one</em> probability measure in play, but remember that there are actually <em>two</em>, and they live on different probability spaces!</p></li>
</ul>
</div>
<p>Now:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Let’s practice! Have a go at problems 5-7 on the worksheet.</p>
</div>
</section>
<section id="discrete-and-continuous-random-variables">
<h2><span class="section-number">4.3. </span>Discrete and continuous random variables<a class="headerlink" href="#discrete-and-continuous-random-variables" title="Permalink to this heading">#</a></h2>
<p>Two types of random variables will be the ones that are most frequently encountered in this class. Their definitions follow below. Before reading them, however, it might be worth reviewing our discussions of discrete and continuous probability measures in <a class="reference internal" href="02-prob-spaces.html#discrete-prob"><span class="std std-numref">Sections 2.6</span></a> and <a class="reference internal" href="02-prob-spaces.html#cont-prob"><span class="std std-numref">2.8</span></a>.</p>
<div class="proof definition admonition" id="discrete-continuous-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.3 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X:S\to \mathbb{R}\)</span> be a random variable.</p>
<ol class="arabic">
<li><p>We shall say <span class="math notranslate nohighlight">\(X\)</span> is <em>discrete</em> if there exists a function <span class="math notranslate nohighlight">\(p:\mathbb{R} \to \mathbb{R}\)</span> such that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    P(X\in A) = \sum_{x\in A} p(x)
    \end{equation*}\]</div>
<p>for all events <span class="math notranslate nohighlight">\(A\subset \mathbb{R}\)</span>. In this case, <span class="math notranslate nohighlight">\(p(x)\)</span> is called the <em>probability mass function of <span class="math notranslate nohighlight">\(X\)</span></em>.</p>
</li>
<li><p>We shall say <span class="math notranslate nohighlight">\(X\)</span> is <em>continuous</em> if there exists a function <span class="math notranslate nohighlight">\(f:\mathbb{R} \to \mathbb{R}\)</span> such that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    P(X\in A) = \int_A f(x) \ \text{d} x
    \end{equation*}\]</div>
<p>for all events <span class="math notranslate nohighlight">\(A\subset \mathbb{R}\)</span>. In this case, <span class="math notranslate nohighlight">\(f(x)\)</span> is called the <em>probability density function of <span class="math notranslate nohighlight">\(X\)</span></em>.</p>
</li>
</ol>
</section>
</div><aside class="margin sidebar">
<p class="sidebar-title">Looking beyond…</p>
<p>Here’s where things get really deep!</p>
<p>Though it seems that discrete and continuous random variables are really rather different because the former type involve discrete summations while the latter involve continuous integrals, there is a very general mathematical theory of integration in which they are <em>united</em>. This is the powerful theory of <a href="https://en.wikipedia.org/wiki/Lebesgue_integration">Lebesgue integration</a>.</p>
<p>Indeed, in this much more general theory, discrete summations actually <em>are</em> integrals of a particular type: They are  integrals “against a <a href="https://en.wikipedia.org/wiki/Counting_measure">counting measure</a>.” Also, in this theory the <em>probability mass functions</em> of discrete random variables and the <em>probability density functions</em> of continuous ones are united, for they are both examples of <a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem#">Radon-Nikodym derivatives</a> of measures that are <a href="https://en.wikipedia.org/wiki/Absolute_continuity#Absolute_continuity_of_measures">absolutely continuous</a> with respect to an ambient measure, either a <a href="https://en.wikipedia.org/wiki/Counting_measure">counting measure</a> in the discrete case, or the <a href="https://en.wikipedia.org/wiki/Lebesgue_measure">Lebesgue measure</a> in the continuous one.</p>
</aside>
<p>Notice that a random variable <span class="math notranslate nohighlight">\(X\)</span> is discrete if and only if its probability measure <span class="math notranslate nohighlight">\(P_X\)</span> is discrete in the sense defined in <a class="reference internal" href="02-prob-spaces.html#discrete-prob"><span class="std std-numref">Section 2.6</span></a>, while it is continuous if and only if <span class="math notranslate nohighlight">\(P_X\)</span> is continuous in the sense defined in <a class="reference internal" href="02-prob-spaces.html#cont-prob"><span class="std std-numref">Section 2.8</span></a>.</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Let’s get some practice recognizing discrete and continuous random variables, and computing some of their probability measures. Do problems 8 and 9 on the worksheet.</p>
</div>
<p>As I mentioned, discrete and continuous random variables will be the only types of random variables that we work with in this class—at least in problems where we need to <em>compute</em> things. As we continue, you will notice the contrast in the definition above, where discrete random variables involve summations <span class="math notranslate nohighlight">\(\sum\)</span> and continuous random variables involve integrals <span class="math notranslate nohighlight">\(\int\)</span>, will be replicated over and over again. This is another good intuition to have in mind for these two types of random variables: The discrete random variables are those in which you “add things” to compute various quantities, whereas continuous random variables are those in which you must “integrate things.”</p>
</section>
<section id="distribution-and-quantile-functions">
<span id="dist-func-rv"></span><h2><span class="section-number">4.4. </span>Distribution and quantile functions<a class="headerlink" href="#distribution-and-quantile-functions" title="Permalink to this heading">#</a></h2>
<p>If <span class="math notranslate nohighlight">\(X\)</span> is any type of random variable (discrete, continuous, or neither), then its probability measure <span class="math notranslate nohighlight">\(P_X\)</span> lives on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. As such, it has both distribution and quantile functions. We studied these latter types of functions in <a class="reference internal" href="02-prob-spaces.html#dist-quant"><span class="std std-numref">Section 2.10</span></a>. But in case you forgot their definitions, we review them in this section in the context of random variables.</p>
<div class="proof definition admonition" id="cdf-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.4 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable. The <em>distribution function of <span class="math notranslate nohighlight">\(X\)</span></em> is the function <span class="math notranslate nohighlight">\(F:\mathbb{R} \to \mathbb{R}\)</span> defined by</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
F(x) = P(X \leq x).
\end{equation*}\]</div>
<p>In particular:</p>
<ol class="arabic">
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is discrete with probability mass function <span class="math notranslate nohighlight">\(p(x)\)</span>, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    F(x) = \sum_{y \leq x} p(y),
    \end{equation*}\]</div>
<p>where the sum ranges over all <span class="math notranslate nohighlight">\(y\in \mathbb{R}\)</span> with <span class="math notranslate nohighlight">\(y\leq x\)</span>.</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is continuous with density function <span class="math notranslate nohighlight">\(f(x)\)</span>, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    F(x) = \int_{-\infty}^x f(y) \ \text{d} y.
    \end{equation*}\]</div>
</li>
</ol>
</section>
</div><p>And here’s the definition of quantile functions:</p>
<div class="proof definition admonition" id="quantile-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.5 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable with distribution function <span class="math notranslate nohighlight">\(F:\mathbb{R} \to [0,1]\)</span>. The <em>quantile function of <span class="math notranslate nohighlight">\(X\)</span></em> is the function <span class="math notranslate nohighlight">\(Q: [0,1] \to \mathbb{R}\)</span> defined so that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
Q(p) = \min\{x\in \mathbb{R} : p \leq F(x)\}.
\end{equation*}\]</div>
<p>In other words, the value <span class="math notranslate nohighlight">\(x=Q(p)\)</span> is the smallest <span class="math notranslate nohighlight">\(x\in \mathbb{R}\)</span> such that <span class="math notranslate nohighlight">\(p\leq F(x)\)</span>.</p>
<ol class="arabic simple">
<li><p>The value <span class="math notranslate nohighlight">\(Q(p)\)</span> is called the <em><span class="math notranslate nohighlight">\(p\)</span>-th quantile of <span class="math notranslate nohighlight">\(X\)</span></em>.</p></li>
<li><p>The quantile <span class="math notranslate nohighlight">\(Q(0.5)\)</span> is called the <em>median of <span class="math notranslate nohighlight">\(X\)</span></em>.</p></li>
</ol>
</section>
</div><p>Even though we had considerable practice with distribution and quantile functions in <a class="reference internal" href="02-prob-spaces.html#dist-quant"><span class="std std-numref">Section 2.10</span></a>, it won’t hurt to do another practice problem:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problem 10 on the worksheet.</p>
</div>
</section>
<section id="expected-values">
<h2><span class="section-number">4.5. </span>Expected values<a class="headerlink" href="#expected-values" title="Permalink to this heading">#</a></h2>
<p>You should review problem 6 from the worksheet if it isn’t already fresh in your mind. In that problem, we saw the discrete random variable</p>
<div class="math notranslate nohighlight">
\[
X: S \to \mathbb{R}, \quad X = \text{ largest of two numbers}.
\]</div>
<p>We saw that the probability measure of <span class="math notranslate nohighlight">\(X\)</span> is described by the following probability histogram:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../aux-files/custom_style_light.mplstyle&#39;</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">600</span>

<span class="n">support</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png"><img alt="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png" src="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png" style="width: 70%;" /></a>
</figure>
</div>
</div>
<p>Given this information, I want to ask: What is the <em>mean</em> (i.e., <em>average</em>) value of <span class="math notranslate nohighlight">\(X\)</span>? You might say: “Well, the range of <span class="math notranslate nohighlight">\(X\)</span> consists of the numbers <span class="math notranslate nohighlight">\(2,3,4,5\)</span>, so the mean value of <span class="math notranslate nohighlight">\(X\)</span> is just the mean of these four numbers:”</p>
<div class="math notranslate nohighlight">
\[
\frac{2+3+4+5}{4} = 3.5.
\]</div>
<p>But this is wrong!</p>
<p>Don’t believe me? Let’s have the computer randomly draw two balls and record the value of <span class="math notranslate nohighlight">\(X\)</span>. Then, let’s have the computer place the balls back into the urn, and then repeat the procedure, recording another (possibly different) value of <span class="math notranslate nohighlight">\(X\)</span>. Each time the computer draws a pair of balls we will call a <em>trial</em>. Let’s have the computer complete, say, <span class="math notranslate nohighlight">\(n=10\)</span> trials, and then have it compute the mean of the <span class="math notranslate nohighlight">\(n=10\)</span> values of <span class="math notranslate nohighlight">\(X\)</span>. This produces a mean value of <span class="math notranslate nohighlight">\(X\)</span> over <span class="math notranslate nohighlight">\(n=10\)</span> trials.</p>
<p>But why stop with a mean value of <span class="math notranslate nohighlight">\(X\)</span> over only <span class="math notranslate nohighlight">\(n=10\)</span> trials? Why not let <span class="math notranslate nohighlight">\(n\)</span> get bigger? What’s the mean value of <span class="math notranslate nohighlight">\(X\)</span> over <span class="math notranslate nohighlight">\(n=50\)</span> trials, <span class="math notranslate nohighlight">\(n=100\)</span> trials, or even <span class="math notranslate nohighlight">\(n=200\)</span> trials? Answer:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sizes</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">))</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="n">means</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$n=$number of trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mean value of $X$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/5608921f5c6a4c06afa630f84ba21df0a438c69c3968b5ae6461293ba47764d4.png"><img alt="../_images/5608921f5c6a4c06afa630f84ba21df0a438c69c3968b5ae6461293ba47764d4.png" src="../_images/5608921f5c6a4c06afa630f84ba21df0a438c69c3968b5ae6461293ba47764d4.png" style="width: 70%;" /></a>
</figure>
</div>
</div>
<p>As you can see, the mean values of <span class="math notranslate nohighlight">\(X\)</span> appear to stabilize near <span class="math notranslate nohighlight">\(4\)</span> (not <span class="math notranslate nohighlight">\(3.5\)</span>!) as the number of trials increases. And it is <em>this</em> theoretical limiting value of <span class="math notranslate nohighlight">\(4\)</span> that we will call the <em>true</em> mean value of the random variable <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Then, here’s the central question:</p>
<blockquote>
<div><p><strong>Q</strong>: How could we have computed this (theoretical, limiting) mean value without resorting to a computer simulation?</p>
</div></blockquote>
<p>The answer is surprisingly easy. First, let’s take a look at the <em>wrong</em> mean value that we computed above:</p>
<div class="math notranslate nohighlight">
\[
\frac{2+3+4+5}{4} = 2\left(\frac{1}{4}\right) +3\left(\frac{1}{4}\right)+4\left(\frac{1}{4}\right)+5\left(\frac{1}{4}\right).
\]</div>
<p>The expression on the right-hand side is called a <em>weighted sum</em> of the numbers <span class="math notranslate nohighlight">\(2,3,4,5\)</span>, because it is the sum of these four numbers, but there are (multiplicative) weights placed on each of them, namely the number <span class="math notranslate nohighlight">\(1/4\)</span>. Notice that there are four <span class="math notranslate nohighlight">\(1/4\)</span>’s appearing in the weighted sum, and that</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{4} + \frac{1}{4} + \frac{1}{4} + \frac{1}{4} = 1.
\]</div>
<p>We interpret these four <span class="math notranslate nohighlight">\(1/4\)</span>’s as the <em>uniform</em> probability measure on the range <span class="math notranslate nohighlight">\(2,3,4,5\)</span>, where each of these four numbers gets a probability of <span class="math notranslate nohighlight">\(1/4\)</span>. Therefore, the <em>wrong</em> mean value computed above is wrong simply because it uses the wrong probability measure! The probability measure on the range of <span class="math notranslate nohighlight">\(X\)</span> is <em>not</em> uniform, rather, it is given by the values in the probability histogram from above:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png"><img alt="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png" src="../_images/480bf5436cf8fa177d2975fede8dc74a66016b563f13b21aac81f4d3ca66c281.png" style="width: 70%;" /></a>
</figure>
</div>
</div>
<p>So, what happens if we substitute the <em>correct</em> probability measure into the weighted sum? Here it is:</p>
<div class="math notranslate nohighlight">
\[
2\left(0.1\right) +3\left(0.2\right)+4\left(0.3\right)+5\left(0.4\right) =4.
\]</div>
<p>And just like that, we get the correct answer!</p>
<p>Just by looking at the probability histogram of <span class="math notranslate nohighlight">\(X\)</span>, you can <em>see</em> that the mean value must be bigger than <span class="math notranslate nohighlight">\(3.5\)</span> (which lies smack in the middle of the histogram). This is because the probability measure of <span class="math notranslate nohighlight">\(X\)</span> has more “probability mass” concentrated on the right-hand side of the histogram, which will “pull” the mean value in that direction. In other words, the values of <span class="math notranslate nohighlight">\(X\)</span> on the right-hand side of the histogram have more “weight” and thus contribute more to the mean value. Here’s a plot of the probability histogram again, but with a vertical line representing the mean value:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expected_val</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span> <span class="o">*</span> <span class="n">p</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">expected_val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/f5059517c7bd7080ba9f0a26707bc995062d6196a447ad1a635e14db4256267e.png"><img alt="../_images/f5059517c7bd7080ba9f0a26707bc995062d6196a447ad1a635e14db4256267e.png" src="../_images/f5059517c7bd7080ba9f0a26707bc995062d6196a447ad1a635e14db4256267e.png" style="width: 70%;" /></a>
</figure>
</div>
</div>
<p>Let me give you four more random variables, <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, <span class="math notranslate nohighlight">\(X_3\)</span>, and <span class="math notranslate nohighlight">\(X_4\)</span>, along with their probability histograms and vertical lines representing their mean values:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">[[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]]</span>
<span class="n">support</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">support</span><span class="p">])</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="n">expected_val</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span> <span class="o">*</span> <span class="n">p</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">)])</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">expected_val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$X_1$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$X_2$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$X_3$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$X_4$&#39;</span><span class="p">)</span>   
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/cf3a02273eb1562bce00bf0124a3443a974cd0886b83d428d68c66afaf74c352.png"><img alt="../_images/cf3a02273eb1562bce00bf0124a3443a974cd0886b83d428d68c66afaf74c352.png" src="../_images/cf3a02273eb1562bce00bf0124a3443a974cd0886b83d428d68c66afaf74c352.png" style="width: 100%;" /></a>
</figure>
</div>
</div>
<p>Notice that the mean values of the random variables <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> in the first row are “pulled” in the direction of higher “probability mass,” while the mean values of <span class="math notranslate nohighlight">\(X_3\)</span> and <span class="math notranslate nohighlight">\(X_4\)</span> in the second row lie on the “axes of symmetry” of the probability distributions. Think of the mean value of a random variable as the “center of mass” of its probability distribution.</p>
<p>Before giving you the precise definitions, you need to know that mean values are also called <em>expected values</em>. (Quantum physicists also call them <em>expectation values</em>.) So, in the official, technical lingo, what we were computing above was the <em>expected value</em> of the random variable <span class="math notranslate nohighlight">\(X\)</span>.</p>
<div class="proof definition admonition" id="expected-val-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.6 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable.</p>
<ul>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is discrete with probability mass function <span class="math notranslate nohighlight">\(p(x)\)</span>, then its <em>expected value</em>, denoted <span class="math notranslate nohighlight">\(E(X)\)</span>, is the sum</p>
<div class="math notranslate nohighlight" id="equation-sum-01-eqn">
<span class="eqno">(4.3)<a class="headerlink" href="#equation-sum-01-eqn" title="Permalink to this equation">#</a></span>\[
  E(X) = \sum_{x\in \mathbb{R}} x\cdot p(x).
  \]</div>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is continuous with probability density function <span class="math notranslate nohighlight">\(f(x)\)</span>, then its <em>expected value</em>, denoted <span class="math notranslate nohighlight">\(E(X)\)</span>, is the integral</p>
<div class="math notranslate nohighlight">
\[
  E(X) = \int_{\mathbb{R}} x\cdot f(x) \ \text{d} x.
  \]</div>
</li>
</ul>
<p>In both cases, the expected value <span class="math notranslate nohighlight">\(E(X)\)</span> is also often called the <em>mean value</em> of <span class="math notranslate nohighlight">\(X\)</span> (or just <em>mean</em>) and denoted <span class="math notranslate nohighlight">\(\mu_X\)</span> or just <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</section>
</div><p>Here we see the “sum vs. integral” dichotomy between discrete and continuous random variables that we saw in previous sections.</p>
<aside class="margin sidebar">
<p class="sidebar-title">Looking beyond…</p>
<p>Though I have only defined expected values of discrete and continuous random variables, technically <em>all</em> random variables have expected values (though there may be convergence issues). However, in order to even <a href="https://en.wikipedia.org/wiki/Expected_value#Arbitrary_real-valued_random_variables"><em>define</em></a> these expected values, we would need the theory of Lebesgue integration that I mentioned above.</p>
</aside>
<p>Now, the sum <span class="math notranslate nohighlight">\(\sum_{x\in \mathbb{R}}\)</span> in <a class="reference internal" href="#equation-sum-01-eqn">(4.3)</a> simply means that we are adding up all terms of the form <span class="math notranslate nohighlight">\(x\cdot p(x)\)</span>, as <span class="math notranslate nohighlight">\(x\)</span> ranges over all real numbers in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. But remember, the random variable <span class="math notranslate nohighlight">\(X\)</span> is assumed to be <em>discrete</em>, so there are actually either only finitely many <span class="math notranslate nohighlight">\(p(x)\)</span>’s that are nonzero—in which case the sum is actually finite—or there are a countable infinity that are nonzero—in which case the sum is of the form <span class="math notranslate nohighlight">\(\sum_{n=1}^\infty\)</span>. In the latter case, there is the possibility that the expected value <span class="math notranslate nohighlight">\(E(X)\)</span> doesn’t exist, because the infinite series doesn’t converge. However, at this level, except for a few special cases, we won’t worry about such things. We shall <em>always</em> assume in this class that the infinite series converge and all our expected values exist. Even more, we shall assume that the series converge <em>absolutely</em>, which you might(?) remember means that the series of absolute values</p>
<div class="math notranslate nohighlight">
\[
\sum_{x\in \mathbb{R}} |x\cdot p(x)| = \sum_{x\in \mathbb{R}} |x|\cdot p(x)
\]</div>
<p>converges. One byproduct of absolute convergence is that the order of the summands in the infinite series doesn’t matter; if you’ve taken real analysis and have studied <a href="https://en.wikipedia.org/wiki/Riemann_series_theorem#">rearrangements</a>, this might sound familiar to you. If not, don’t worry about it.</p>
<p>Likewise, in the continuous case there is the possibility that <span class="math notranslate nohighlight">\(E(X)\)</span> doesn’t exist, in the sense that the improper integral</p>
<div class="math notranslate nohighlight">
\[
\int_{-\infty}^\infty |x| \cdot f(x) \ \text{d} x
\]</div>
<p>doesn’t converge. But as in the discrete case, we won’t worry about these situations.</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problems 11-15 on the worksheet.</p>
</div>
</section>
<section id="the-algebra-of-random-variables">
<h2><span class="section-number">4.6. </span>The algebra of random variables<a class="headerlink" href="#the-algebra-of-random-variables" title="Permalink to this heading">#</a></h2>
<p>Remember that, technically, random variables are <em>functions</em>. But as you will see as you go through your training in probability and statistics, we often want to treat them <em>as if</em> they were numbers and add and subtract them, multiply and divide them, and even plug them into functions like we would a numerical variable. In short: We want to develop an <em>algebra</em> of random variables.</p>
<p>Let’s see how this works in the case of <em>addition</em> of random variables. Given two random variables</p>
<div class="math notranslate nohighlight">
\[
X,Y: S \to \mathbb{R}
\]</div>
<p>on a probability space <span class="math notranslate nohighlight">\(S\)</span>, we ask: What should the sum <span class="math notranslate nohighlight">\(X+Y\)</span> be? Well, it should <em>itself</em> be a random variable on <span class="math notranslate nohighlight">\(S\)</span>, so, in particular, it needs to be a function</p>
<div class="math notranslate nohighlight">
\[
X+Y : S \to \mathbb{R}.
\]</div>
<p>To evaluate <span class="math notranslate nohighlight">\(X+Y\)</span> at a sample point <span class="math notranslate nohighlight">\(s\in S\)</span>, the most natural thing to do is to add the corresponding outputs of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, i.e., to define</p>
<div class="math notranslate nohighlight" id="equation-add-eqn">
<span class="eqno">(4.4)<a class="headerlink" href="#equation-add-eqn" title="Permalink to this equation">#</a></span>\[
(X+Y)(s) = X(s) + Y(s).
\]</div>
<p>This addition operation on random variables is called the <em>pointwise sum</em>.</p>
<p>Yikes. This seems overly complicated. But it’s pretty easy to bring down to earth if we imagine for simplicity that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are discrete random variables defined on a <em>finite</em> sample space. For example, suppose that</p>
<div class="math notranslate nohighlight">
\[
S = \{1,2,3,4\}.
\]</div>
<p>Then, suppose that the outputs of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are given by the values in the table:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
s &amp; X(s) &amp; Y(s) \\ \hline
1 &amp; -1 &amp; 0 \\
2 &amp; 1 &amp; 2 \\
3 &amp; 3 &amp; -1 \\
4 &amp; 0 &amp; 3 
\end{array}
\end{split}\]</div>
<p>Thus, for example, we have <span class="math notranslate nohighlight">\(X(1) = -1\)</span> and <span class="math notranslate nohighlight">\(Y(4) = 3\)</span>. We obtain the pointwise sum <span class="math notranslate nohighlight">\(X+Y\)</span> defined by <a class="reference internal" href="#equation-add-eqn">(4.4)</a> simply by adding the corresponding outputs of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, which is essentially just the rowwise sum:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|ccc}
s &amp; X(s) &amp; Y(s) &amp; (X+Y)(s) \\ \hline
1 &amp; -1 &amp; 0 &amp; -1 + 0 =-1 \\
2 &amp; 1 &amp; 2 &amp; 1+2 = 3 \\
3 &amp; 3 &amp; -1 &amp; 3-1 = 2 \\
4 &amp; 0 &amp; 3 &amp; 0+3=3
\end{array}
\end{split}\]</div>
<p>Ok, cool. So we’ve defined <span class="math notranslate nohighlight">\(X+Y\)</span> as a function on <span class="math notranslate nohighlight">\(S\)</span>. But remember, <span class="math notranslate nohighlight">\(X+Y\)</span> is supposed to be a <em>random variable</em>, so it’s supposed to have a probability measure. We will compute it in:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problem 16 on the worksheet.</p>
</div>
<p>In general, given the probability measures of arbitrary random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, it can be difficult to compute the probability measure of <span class="math notranslate nohighlight">\(X+Y\)</span> except in very special cases.</p>
<aside class="margin sidebar">
<p class="sidebar-title">Looking beyond…</p>
<p>I’ve previewed some of the more advanced <em>analytic</em> theory in the previous few “Looking beyond…” margin notes. Now, how about the <em>algebraic</em> theory?</p>
<ul class="simple">
<li><p>The pointwise addition and product operations defined above give the set of all random variables on a fixed probability space the structure of a <a class="reference external" href="https://en.wikipedia.org/wiki/Commutative_ring">commutative ring</a>.</p></li>
<li><p>The pointwise addition and scaling operations defined above give the set of all random variables on a fixed probability space the structure of an abstract <a class="reference external" href="https://en.wikipedia.org/wiki/Vector_space">vector space</a>.</p></li>
<li><p>These ring and vector space structures interact “coherently” in the sense that together they form a <a class="reference external" href="https://en.wikipedia.org/wiki/Algebra_over_a_field">commutative algebra</a>.</p></li>
</ul>
</aside>
<p>You saw the pointwise product <span class="math notranslate nohighlight">\(XY\)</span> in problem 16 on the worksheet. I bet you can guess the definition of the pointwise difference <span class="math notranslate nohighlight">\(X-Y\)</span> and pointwise quotient <span class="math notranslate nohighlight">\(X/Y\)</span> (watch out for when <span class="math notranslate nohighlight">\(Y=0\)</span> in the latter!). Moreover, given a constant <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span>, there is also a very natural definition of <span class="math notranslate nohighlight">\(cY\)</span>, where <span class="math notranslate nohighlight">\(Y\)</span> is a random variable; indeed, it is given pointwise by</p>
<div class="math notranslate nohighlight" id="equation-scale-eqn">
<span class="eqno">(4.5)<a class="headerlink" href="#equation-scale-eqn" title="Permalink to this equation">#</a></span>\[
(cY)(s) = cY(s).
\]</div>
<p>Taking <span class="math notranslate nohighlight">\(c=4\)</span> in the example above, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
s &amp; Y(s) &amp; (4Y)(s) \\ \hline
1 &amp; 0 &amp; 4\cdot 0 = 0 \\
2 &amp; 2 &amp; 4\cdot 2 = 8 \\
3 &amp; -1 &amp; 4 \cdot(-1) = -4 \\
4 &amp; 3 &amp; 4\cdot 3 = 12
\end{array}
\end{split}\]</div>
<p>It thus appears that the pointwise scaling operation <a class="reference internal" href="#equation-scale-eqn">(4.5)</a> is just columnwise scaling.</p>
<p>So there we have it: We now have an <em>algebra</em> of random variables. Easy enough. But be aware that if your random variables are <em>continuous</em>, then we obviously cannot represent them via a finite table of values like we did above, and perform rowwise and columnwise operations. In this case, your only option is to resort to the defining equations for the algebraic operations:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((X\pm Y)(s) = X(s) \pm Y(s)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\((XY)(s) = X(s) Y(s)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\((X/Y)(s) = X(s)/Y(s)\)</span>, when <span class="math notranslate nohighlight">\(Y(s)\neq 0\)</span>,</p></li>
</ul>
<p>for <span class="math notranslate nohighlight">\(s\in S\)</span>.</p>
</section>
<section id="functions-of-random-variables">
<h2><span class="section-number">4.7. </span>Functions of random variables<a class="headerlink" href="#functions-of-random-variables" title="Permalink to this heading">#</a></h2>
<p>In addition to an algebra of random variables, I mentioned at the beginning of the previous section that we will want to plug random variables into functions, just like we would numerical variables. It’s difficult to convey at this early stage exactly <em>why</em> we would want to do this, but I encourage patience. You’ll see soon enough how often this procedure is used!</p>
<p>To see how this works, let’s suppose a random variable <span class="math notranslate nohighlight">\(X\)</span> is defined on a finite sample space <span class="math notranslate nohighlight">\(S=\{1,2,3,4\}\)</span> with:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|c}
s &amp; X(s)  \\ \hline
1 &amp; 0  \\
2 &amp; 2  \\
3 &amp; -1  \\
4 &amp; 3 
\end{array}
\end{split}\]</div>
<p>Now, consider the good ol’ quadratic function <span class="math notranslate nohighlight">\(g(x) = x^2\)</span>. How should I make sense of <span class="math notranslate nohighlight">\(g(X) = X^2\)</span>?</p>
<p>First, notice that the expression <span class="math notranslate nohighlight">\(g(X)\)</span> technically doesn’t make any sense. This is because <span class="math notranslate nohighlight">\(X\)</span> is a <em>function</em>, while the domain of <span class="math notranslate nohighlight">\(g\)</span> is a set of <em>numbers</em>, so mathematically speaking you cannot plug <span class="math notranslate nohighlight">\(X\)</span> into <span class="math notranslate nohighlight">\(g\)</span> since <span class="math notranslate nohighlight">\(X\)</span> is not in the domain of <span class="math notranslate nohighlight">\(g\)</span>. Instead, what <span class="math notranslate nohighlight">\(g(X)\)</span> <em>really</em> represents is the composite function <span class="math notranslate nohighlight">\(g\circ X\)</span> which is a legitimate function on <span class="math notranslate nohighlight">\(S\)</span> like any random variable is supposed to be.</p>
<p>Given this interpretation, how would we actually compute <span class="math notranslate nohighlight">\(g(X) = X^2\)</span> given the table of values above? Easy! Simply apply the squaring function <span class="math notranslate nohighlight">\(g(x) = x^2\)</span> rowwise to each output of <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
s &amp; X(s) &amp; X^2(s) \\ \hline
1 &amp; 0 &amp; 0^2 = 0  \\
2 &amp; 2 &amp; 2^2 = 4  \\
3 &amp; -1 &amp; (-1)^2 = 1  \\
4 &amp; 3 &amp; 3^2 = 9 
\end{array}
\end{split}\]</div>
<p>While this is pretty straightforward in the case that <span class="math notranslate nohighlight">\(X\)</span> is defined on a finite probability space, in the case that <span class="math notranslate nohighlight">\(X\)</span> is <em>continuous</em>, we cannot compute <span class="math notranslate nohighlight">\(g(X)\)</span> using a finite table of values. In this case, you must resort to the <em>definition</em>:</p>
<div class="math notranslate nohighlight">
\[
g(X) = g \circ X.
\]</div>
<p>Now:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Have a go at problem 17 on the worksheet.</p>
</div>
</section>
<section id="expectations-of-functions-of-random-variables-and-the-lotus">
<h2><span class="section-number">4.8. </span>Expectations of functions of random variables and the LotUS<a class="headerlink" href="#expectations-of-functions-of-random-variables-and-the-lotus" title="Permalink to this heading">#</a></h2>
<p>In the next two sections, we list some of the most useful properties of expectations of functions of random variables. Two such properties will be of particular importance: The first is encoded in something called the “Law of the Unconscious Statistician,” which we will talk about in this section, while the second property is called <em>linearity</em> and will be discussed in the next section.</p>
<p>Here’s the situation: Suppose we have a discrete random variable <span class="math notranslate nohighlight">\(X:S\to \mathbb{R}\)</span> on a probability space, and a real-valued function <span class="math notranslate nohighlight">\(y=g(x)\)</span> on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. As I explained above, we can “plug <span class="math notranslate nohighlight">\(X\)</span> into <span class="math notranslate nohighlight">\(g\)</span>,” obtaining the “transformed” random variable <span class="math notranslate nohighlight">\(Y = g(X)\)</span> which is really the composite <span class="math notranslate nohighlight">\(g\circ X\)</span> in disguise. The goal in this section is to derive a formula for the expected value <span class="math notranslate nohighlight">\(E(Y) = E(g(X))\)</span>.</p>
<p>Now, <strong>by definition</strong>, this expected value is given by the formula</p>
<div class="math notranslate nohighlight" id="equation-right-eqn">
<span class="eqno">(4.6)<a class="headerlink" href="#equation-right-eqn" title="Permalink to this equation">#</a></span>\[
E(Y) = \sum_{y\in \mathbb{R}} y \cdot P\left(Y=y\right).
\]</div>
<p>However, if you weren’t paying close attention and were mindlessly and unconsciously computing things, you might be tempted by the (valid!) equations <span class="math notranslate nohighlight">\(Y = g(X)\)</span> and <span class="math notranslate nohighlight">\(y=g(x)\)</span> to compute this expected value by</p>
<div class="math notranslate nohighlight" id="equation-wrong1-eqn">
<span class="eqno">(4.7)<a class="headerlink" href="#equation-wrong1-eqn" title="Permalink to this equation">#</a></span>\[
E(g(X)) = \sum_{x\in \mathbb{R}} g(x)\cdot P(X=x).
\]</div>
<p>It could happen, right?</p>
<p>But you <em>need</em> to notice that it is <em>not</em> obvious that the expression on the right-hand side of <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> correctly computes the expected value <span class="math notranslate nohighlight">\(E(Y) = E(g(X))\)</span>. For one, notice that the sum in <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> iterates over all <span class="math notranslate nohighlight">\(x\in \mathbb{R}\)</span>, and that these values are inserted into <span class="math notranslate nohighlight">\(g\)</span> to obtain <span class="math notranslate nohighlight">\(y=g(x)\)</span>. But there is no reason to believe that you obtain <em>all</em> values of <span class="math notranslate nohighlight">\(y\in \mathbb{R}\)</span> in this way, and yet this is what the <em>correct</em> formula <a class="reference internal" href="#equation-right-eqn">(4.6)</a> demands.</p>
<p>So, you see there is no <em>obvious</em> reason why the two formulas <a class="reference internal" href="#equation-right-eqn">(4.6)</a> and <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> should be the same. And yet, if you mistakenly compute <span class="math notranslate nohighlight">\(E(Y) =E(g(X))\)</span> using <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> and then return later in a panic to re-do your computations using <a class="reference internal" href="#equation-right-eqn">(4.6)</a>, you’ll find that they were <em>right</em> the entire time! This is because these two formulas secretly <em>are</em> the same, but exactly <em>why</em> they are equal is not obvious.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>And by the way: Though I am a mathematician by training and get annoyed rather easily with sloppy mathematical rigor, I did <em>not</em> <a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">make up</a> this name. :)</p>
</aside>
<p>The fact that the formula <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> correctly computes the expected value <span class="math notranslate nohighlight">\(E(Y) = E(g(X))\)</span> is called the “Law of the Unconscious Statistician,” named in honor of all those unconscious statisticians who believe the formulas <a class="reference internal" href="#equation-right-eqn">(4.6)</a> and <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a>are <strong>obviously</strong> the same thing!</p>
<p>Now, let me begin to explain <em>why</em> <a class="reference internal" href="#equation-wrong1-eqn">(4.7)</a> correctly computes the expected value by drawing a few pictures. First, remember that <span class="math notranslate nohighlight">\(Y=g(X)\)</span> is a real-valued function on <span class="math notranslate nohighlight">\(S\)</span> like any other, so I would picture it like this:</p>
<a class="reference internal image-reference" href="../_images/trans0.svg"><img alt="../_images/trans0.svg" class="align-center" src="../_images/trans0.svg" width="75%" /></a>
<p> </p>
<p>In the <em>definition</em> <a class="reference internal" href="#equation-right-eqn">(4.6)</a> of <span class="math notranslate nohighlight">\(E(g(X))\)</span>, notice that we must compute the probabilities</p>
<div class="math notranslate nohighlight" id="equation-yeah-eqn">
<span class="eqno">(4.8)<a class="headerlink" href="#equation-yeah-eqn" title="Permalink to this equation">#</a></span>\[
P(Y=y) = P(g(X)=y)
\]</div>
<p>for each <span class="math notranslate nohighlight">\(y\in \mathbb{R}\)</span>. This probability is precisely the probability of the set in <span class="math notranslate nohighlight">\(S\)</span> consisting of those sample points <span class="math notranslate nohighlight">\(s\)</span> that “hit” <span class="math notranslate nohighlight">\(y\)</span> when mapped via <span class="math notranslate nohighlight">\(g(X)\)</span>. I have shaded this set in:</p>
<a class="reference internal image-reference" href="../_images/trans3.svg"><img alt="../_images/trans3.svg" class="align-center" src="../_images/trans3.svg" width="75%" /></a>
<p> </p>
<p>It could be that there are actually <em>no</em> sample points in <span class="math notranslate nohighlight">\(S\)</span> that “hit” <span class="math notranslate nohighlight">\(y\)</span>; in this case, the shaded set in <span class="math notranslate nohighlight">\(S\)</span> is empty, and the probability <a class="reference internal" href="#equation-yeah-eqn">(4.8)</a> is <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Now, remember also that <span class="math notranslate nohighlight">\(g(X)\)</span> technically stands for the composite function <span class="math notranslate nohighlight">\(g\circ X\)</span>, so on its way from <span class="math notranslate nohighlight">\(S\)</span> to <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> (left to right), the random variable <span class="math notranslate nohighlight">\(g(X)\)</span> first takes a detour through <span class="math notranslate nohighlight">\(X\)</span> and another copy of <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>:</p>
<a class="reference internal image-reference" href="../_images/trans1.svg"><img alt="../_images/trans1.svg" class="align-center" src="../_images/trans1.svg" width="75%" /></a>
<p> </p>
<p>If we bring back our point <span class="math notranslate nohighlight">\(y\in \mathbb{R}\)</span> from above, this means that the points in <span class="math notranslate nohighlight">\(S\)</span> that “hit” <span class="math notranslate nohighlight">\(y\)</span> must <em>also</em> first take a detour through <span class="math notranslate nohighlight">\(X\)</span>:</p>
<a class="reference internal image-reference" href="../_images/trans2.svg"><img alt="../_images/trans2.svg" class="align-center" src="../_images/trans2.svg" width="75%" /></a>
<p> </p>
<p>The collection of shaded “intermediate points” in the diagram is denoted <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> and is called the <em>preimage</em> of <span class="math notranslate nohighlight">\(y\)</span> under <span class="math notranslate nohighlight">\(g\)</span>; in set notation:</p>
<div class="math notranslate nohighlight">
\[
g^{-1}(y) \stackrel{\text{def}}{=} \{x\in \mathbb{R} : g(x) = y \}.
\]</div>
<p>Now, any sample point <span class="math notranslate nohighlight">\(s\in S\)</span> that “hits” <span class="math notranslate nohighlight">\(y\)</span> under the function <span class="math notranslate nohighlight">\(g(X)\)</span> must have the property that <span class="math notranslate nohighlight">\(X(s) \in g^{-1}(y)\)</span>. That makes sense, right? If <span class="math notranslate nohighlight">\(s\)</span> “hits” <span class="math notranslate nohighlight">\(y\)</span>, then it must first “hit” one of the shaded “intermediate points” in the preimage <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> in the last picture.</p>
<p>If we suppose that there are only three points <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, and <span class="math notranslate nohighlight">\(x_3\)</span> in the preimage <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> (so that the picture is accurate), then each of the three shaded sets in <span class="math notranslate nohighlight">\(S\)</span> can be labelled as follows:</p>
<a class="reference internal image-reference" href="../_images/trans4.svg"><img alt="../_images/trans4.svg" class="align-center" src="../_images/trans4.svg" width="100%" /></a>
<p> </p>
<p>Therefore, we have the equation of sets</p>
<div class="math notranslate nohighlight" id="equation-easy-eqn">
<span class="eqno">(4.9)<a class="headerlink" href="#equation-easy-eqn" title="Permalink to this equation">#</a></span>\[
\{s\in S: g(X(s)) = y \} =  \bigcup_{k=1}^3 \{s\in S : X(s) = x_k\}.
\]</div>
<p>There’s a lot going on in this equality, so make sure that you pause and ponder it for a while if you need to.</p>
<p>But it might be the case that the preimage <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> doesn’t consist only of three <span class="math notranslate nohighlight">\(x\)</span>-values; indeed, it could even contain infinitely many values! Since I don’t know ahead of time how many points it contains, it is better to rewrite <a class="reference internal" href="#equation-easy-eqn">(4.9)</a> as</p>
<div class="math notranslate nohighlight" id="equation-harder-eqn">
<span class="eqno">(4.10)<a class="headerlink" href="#equation-harder-eqn" title="Permalink to this equation">#</a></span>\[
\{s\in S: g(X(s)) = y \} =  \bigcup_{x\in g^{-1}(y)} \{s\in S : X(s) = x\}.
\]</div>
<p>This looks like a more complicated equality, but the intuition behind it is <em>exactly</em> the same as <a class="reference internal" href="#equation-easy-eqn">(4.9)</a>.</p>
<p>If I now apply the probability measure <span class="math notranslate nohighlight">\(P\)</span> to both sides of this last equality <a class="reference internal" href="#equation-harder-eqn">(4.10)</a>, and use the fact that the union on the right-hand side is disjoint, I get:</p>
<div class="math notranslate nohighlight" id="equation-fundamental-eqn">
<span class="eqno">(4.11)<a class="headerlink" href="#equation-fundamental-eqn" title="Permalink to this equation">#</a></span>\[
P\left(g(X)=y\right) = \sum_{x\in g^{-1}(y)} P(X=x).
\]</div>
<p>Now, it turns out that <em>this</em> is the key equality for unlocking the proof of the Law of the Unconscious Statistician. There are two versions of this law, one for discrete random variables and the other for continuous ones. Let’s formally state the law before I continue with the proof:</p>
<div class="proof theorem admonition" id="lotus-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.1 </span> (Law of the Unconscious Statistician (LotUS))</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable and <span class="math notranslate nohighlight">\(g:\mathbb{R}^2 \to \mathbb{R}\)</span> a function.</p>
<ul>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is discrete with mass function <span class="math notranslate nohighlight">\(p(x)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
  E(g(X)) = \sum_{x\in \mathbb{R}} g(x)\cdot p(x).
  \]</div>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> is continuous with density function <span class="math notranslate nohighlight">\(f(x)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
  E(g(X)) = \int_{\mathbb{R}} g(x) \cdot f(x) \ \text{d} x.
  \]</div>
</li>
</ul>
</section>
</div><aside class="margin sidebar">
<p class="sidebar-title">Looking beyond… </p>
<p>From a much more high-brow point of view, the Law of the Unconscious Statistician is a corollary of a simple <a href="https://en.wikipedia.org/wiki/Pushforward_measure#Main_property:_change-of-variables_formula">change-of-variables formula</a> for Lebesgue integrals.</p>
</aside>
<p>We will only prove the result in the case that <span class="math notranslate nohighlight">\(X\)</span> is discrete. And in view of the work we did above, the proof is easy: Beginning with the definition <a class="reference internal" href="#equation-right-eqn">(4.6)</a> of <span class="math notranslate nohighlight">\(E(g(X))\)</span> and using <a class="reference internal" href="#equation-fundamental-eqn">(4.11)</a>, we compute:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
E(g(X)) &amp;= \sum_{y\in \mathbb{R}} y\cdot P\left(g(X)=y\right) \\
&amp;= \sum_{y\in \mathbb{R}} \sum_{x\in g^{-1}(y)} y\cdot P(X=x) \\
&amp;= \sum_{x\in \mathbb{R}} g(x)\cdot P(X=x),
\end{align*}\]</div>
<p>where the last equality follows from the observation that <span class="math notranslate nohighlight">\(g(x)=y\)</span> if <span class="math notranslate nohighlight">\(x\in g^{-1}(y)\)</span>.</p>
<p>Et voilà! Just like that, we’ve proved the LotUS by simply drawing a bunch of pictures (at least in the discrete case)! Now try the following:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problems 18 and 19 on the worksheet.</p>
</div>
</section>
<section id="linearity-of-expectation">
<span id="linear-of-exp"></span><h2><span class="section-number">4.9. </span>Linearity of expectation<a class="headerlink" href="#linearity-of-expectation" title="Permalink to this heading">#</a></h2>
<p>We’ve learned that if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are two random variables, then their pointwise sum <span class="math notranslate nohighlight">\(Z=X+Y\)</span> is also a random variable. In the discrete case, we may compute the expectations of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, respectively, via the definition as</p>
<div class="math notranslate nohighlight" id="equation-huh1-eqn">
<span class="eqno">(4.12)<a class="headerlink" href="#equation-huh1-eqn" title="Permalink to this equation">#</a></span>\[
E(X) = \sum_{x\in \mathbb{R}}x\cdot P(X=x) \quad \text{and} \quad E(Y) = \sum_{y\in \mathbb{R}}y\cdot P(Y=y).
\]</div>
<p>How would we compute the expectation of the sum <span class="math notranslate nohighlight">\(Z = X+Y\)</span>? By definition, it would be</p>
<div class="math notranslate nohighlight" id="equation-huh2-eqn">
<span class="eqno">(4.13)<a class="headerlink" href="#equation-huh2-eqn" title="Permalink to this equation">#</a></span>\[
E(X+Y) = \sum_{z\in \mathbb{R}} z \cdot P(X+Y=z).
\]</div>
<p>But it is not clear at first glance that there is any sort of simple relationship between the three expectations in <a class="reference internal" href="#equation-huh1-eqn">(4.12)</a> and <a class="reference internal" href="#equation-huh2-eqn">(4.13)</a>. Nevertheless, as I will explain in a later chapter—after we’ve learned about <em>joint distributions</em>—these expectations are related through the first equation in:</p>
<div class="proof theorem admonition" id="linearity-init-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.2 </span> (Linearity of Expectation)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> be two random variables and let <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span> be a constant. Then:</p>
<div class="math notranslate nohighlight" id="equation-linear-eqn">
<span class="eqno">(4.14)<a class="headerlink" href="#equation-linear-eqn" title="Permalink to this equation">#</a></span>\[
E(X+Y) = E(X) + E(Y),
\]</div>
<p>and</p>
<div class="math notranslate nohighlight" id="equation-homog-eqn">
<span class="eqno">(4.15)<a class="headerlink" href="#equation-homog-eqn" title="Permalink to this equation">#</a></span>\[
E(cX) = c E(X).
\]</div>
</section>
</div><p>You couldn’t possibly hope for any simpler relationship than <a class="reference internal" href="#equation-linear-eqn">(4.14)</a>! But as I just mentioned, I can’t yet explain <em>why</em> this equation holds. The explanation will come later, in the form of <a class="reference internal" href="08-more-prob.html#linear-exp-thm">Theorem 8.3</a>.</p>
<p>However, we <em>can</em> prove <a class="reference internal" href="#equation-homog-eqn">(4.15)</a> quite easily: Just use the LotUS with the function <span class="math notranslate nohighlight">\(g(x) = cx\)</span>. Can you supply the details to this argument?</p>
<p>Now, even though we can’t prove <a class="reference internal" href="#equation-linear-eqn">(4.14)</a> at this point, we won’t need it quite yet, so we’re not in any danger. Instead, the following “weak” form of linearity is all we need. (For convenience, I’ve taken the identity <a class="reference internal" href="#equation-homog-eqn">(4.15)</a>—which you <em>just</em> proved—and included it in this special case.)</p>
<div class="proof theorem admonition" id="weak-linear-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.3 </span> (“Weak” Linearity of Expectation)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a discrete or continuous random variable, let <span class="math notranslate nohighlight">\(y=g_1(x)\)</span> and <span class="math notranslate nohighlight">\(y=g_2(x)\)</span> be two real-valued functions, and let <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span> be a constant. Then:</p>
<div class="math notranslate nohighlight">
\[
E(g_1(X) + g_2(X)) = E(g_1(X)) + E(g_2(X)),
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
E(cX) = c E(X).
\]</div>
</section>
</div><p>This “weak” form of linearity is a simple application of the LotUS. To see this, first define the real-valued function <span class="math notranslate nohighlight">\(y=g(x)\)</span> by setting</p>
<div class="math notranslate nohighlight">
\[
g(x) = g_1(x) + g_2(x)
\]</div>
<p>for each <span class="math notranslate nohighlight">\(x\)</span>. Then <span class="math notranslate nohighlight">\(g(X) = g_1(X) + g_2(X)\)</span>, and an application of the LotUS (in the continuous case) gives:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
E(g_1(X) + g_2(X)) &amp;= E(g(X)) \notag \\
&amp;= \int_{-\infty}^\infty g(x)\cdot f(x) \ \text{d} x \notag \\
&amp;= \int_{-\infty}^\infty (g_1(x) + g_2(x)) f(x) \ \text{d} x \notag \\
&amp; = \int_{-\infty}^\infty g_1(x)\cdot f(x) \ \text{d} x + \int_{-\infty}^\infty g_2(x)\cdot f(x) \ \text{d} x \\
&amp;= E(g_1(X)) + E(g_2(X)).
\end{align*}\]</div>
<p>Can you see exactly where I used the LotUS? And can you adapt this argument on your own to cover the discrete case?</p>
<p>We need just one more fact before proceeding to practice problems. To state it, observe that any constant <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span> may be considered a random variable. Indeed, it may be identified with the unique random variable that sends the <em>entire</em> sample space to the constant <span class="math notranslate nohighlight">\(c\)</span>:</p>
<a class="reference internal image-reference" href="../_images/constant.svg"><img alt="../_images/constant.svg" class="align-center" src="../_images/constant.svg" width="50%" /></a>
<p> </p>
<p>Thus, every constant <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span> may be considered a <em>constant</em> random variable. Your intuition would then suggest that the mean value of a <em>constant</em> random variable should be pretty easy to compute. And you’d be right!</p>
<div class="proof theorem admonition" id="expectation-constant-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.4 </span> (Expectations of Constants)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(c\in \mathbb{R}\)</span> be a constant, viewed as a constant random variable. Then <span class="math notranslate nohighlight">\(E(c) = c\)</span>.</p>
</section>
</div><p>To see why <span class="math notranslate nohighlight">\(E(c) = c\)</span> holds, simply note that</p>
<div class="math notranslate nohighlight">
\[
E(c) = \sum_{x\in \mathbb{R}} x\cdot P(c=x) = c,
\]</div>
<p>since</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(c=x) = \begin{cases} 1 &amp; : x = c, \\ 0 &amp; : x\neq c. \end{cases}
\end{split}\]</div>
<p>Now:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problem 20 on the worksheet.</p>
</div>
</section>
<section id="variances-and-standard-deviations">
<h2><span class="section-number">4.10. </span>Variances and standard deviations<a class="headerlink" href="#variances-and-standard-deviations" title="Permalink to this heading">#</a></h2>
<p>The last few sections were quite technical, packed with all sorts of definitions, formulas, and equations. But we now return to the same circle of ideas that we used to <em>motivate</em> the definition of the expected value of a random variable <span class="math notranslate nohighlight">\(X\)</span>: It is precisely the “mean value” of <span class="math notranslate nohighlight">\(X\)</span>, and if we think physically, it is the “center of mass” of the probability distribution of <span class="math notranslate nohighlight">\(X\)</span>. As such, it provides a rough description of the “shape” of the distribution, telling us where the majority of the “probability mass” is centered. In fact, for this reason, the expected value of <span class="math notranslate nohighlight">\(X\)</span> is often called a <em>measure of centrality</em>.</p>
<p>In this section, we study two so-called <em>measures of dispersion</em>, or <em>measures of spread</em>. To motivate them, first consider the following two possible probability distributions for a discrete random variable <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
<span class="n">support</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">support</span><span class="p">])</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="n">expected_val</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span> <span class="o">*</span> <span class="n">p</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">)])</span>
    
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">expected_val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/3ce5c1a84c56cd0a8fe9261cafb67b6083d28717b02af86f1f715bbdfd914b79.png"><img alt="../_images/3ce5c1a84c56cd0a8fe9261cafb67b6083d28717b02af86f1f715bbdfd914b79.png" src="../_images/3ce5c1a84c56cd0a8fe9261cafb67b6083d28717b02af86f1f715bbdfd914b79.png" style="width: 100%;" /></a>
</figure>
</div>
</div>
<p>Notice that both probability distributions have the same expected value <span class="math notranslate nohighlight">\(\mu = 0.5\)</span>, as indicated by the two vertical lines. But the second distribution is clearly more dispersed—or “spread out”—as compared to the first.</p>
<blockquote>
<div><p><strong>Q</strong>: How might we measure the spread of these distributions?</p>
</div></blockquote>
<p>Here’s one way. Imagine choosing random numbers in the range of <span class="math notranslate nohighlight">\(X\)</span>, which according to the histograms above, is equal to the set</p>
<div class="math notranslate nohighlight">
\[
\{0.1,0.2,\ldots,0.9\}.
\]</div>
<p>If you choose these numbers according to the left-hand distribution, then <em>on average</em>, your numbers should be relatively close to the mean value <span class="math notranslate nohighlight">\(\mu=0.5\)</span>. On the other hand, if you choose these numbers according to the right-hand distribution, then <em>on average</em>, your numbers would likely spend more time further away from the mean value <span class="math notranslate nohighlight">\(\mu=0.5\)</span>. So, what we’re really talking about is the <em>average distance from the mean</em>.</p>
<p>Now, if <span class="math notranslate nohighlight">\(x\)</span> is one of your chosen numbers in the range of <span class="math notranslate nohighlight">\(X\)</span>, then its distance to the mean is <span class="math notranslate nohighlight">\(|x - \mu|\)</span>. (The absolute value bars ensure that this distance is always non-negative, as any distance should be.) Thus, a measure of dispersion of the distributions would be the mean values of the distances <span class="math notranslate nohighlight">\(|x-\mu|\)</span>, as <span class="math notranslate nohighlight">\(x\)</span> varies over the range of <span class="math notranslate nohighlight">\(X\)</span>. But expected values <em>are</em> mean values, and so this suggests that a good measure of dispersion would be the expected value</p>
<div class="math notranslate nohighlight" id="equation-disp-eqn">
<span class="eqno">(4.16)<a class="headerlink" href="#equation-disp-eqn" title="Permalink to this equation">#</a></span>\[
E(|X-\mu|).
\]</div>
<p>In fact, if I compute these expected values for the two probability measures above, I get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
E(|X-\mu|) \approx \begin{cases} 0.08 &amp; : \text{left distribution}, \\ 0.18 &amp; : \text{right distribution}. \end{cases}
\end{split}\]</div>
<p>So, according to the dispersion measure <a class="reference internal" href="#equation-disp-eqn">(4.16)</a>, the right-hand distribution is, in fact, more spread out than the left-hand distribution. This is precisely what we expected!</p>
<p>But while <a class="reference internal" href="#equation-disp-eqn">(4.16)</a> is a perfectly good measure of dispersion, for certain technical reasons it is not the one most often used. (For example, the function <span class="math notranslate nohighlight">\(g(x) = |x-\mu|\)</span> is not differentiable at <span class="math notranslate nohighlight">\(x=\mu\)</span>, which can complicate some things.) Instead, we don’t look at the average <em>actual</em> distance to the mean, rather we look at the average <em>squared distance</em> to the mean:</p>
<div class="proof definition admonition" id="variance-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.7 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable with expected value <span class="math notranslate nohighlight">\(\mu = E(X)\)</span>. The <em>variance</em> of <span class="math notranslate nohighlight">\(X\)</span>, denoted <span class="math notranslate nohighlight">\(V(X)\)</span>, is given by</p>
<div class="math notranslate nohighlight" id="equation-var-eqn">
<span class="eqno">(4.17)<a class="headerlink" href="#equation-var-eqn" title="Permalink to this equation">#</a></span>\[
V(X) = E\left( (X-\mu)^2 \right).
\]</div>
<p>The variance of <span class="math notranslate nohighlight">\(X\)</span> is also denoted <span class="math notranslate nohighlight">\(\sigma^2_X\)</span> or just <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</section>
</div><p>As with expected values, there is the question of whether the variance actually <em>exists</em>. Moreover, technically we have only defined expected values for discrete and continuous random variables, so I <em>should</em> insert those qualifiers in the definition. But we don’t worry about these technicalities at this level.</p>
<p>One of the advantages that the variance <a class="reference internal" href="#equation-var-eqn">(4.17)</a> has over <a class="reference internal" href="#equation-disp-eqn">(4.16)</a> is that the quadratic function <span class="math notranslate nohighlight">\(g(x) = (x-\mu)^2\)</span> is nice and smooth, whereas the absolute value function <span class="math notranslate nohighlight">\(g(x) = |x-\mu|\)</span> is not. Further differences can be uncovered by considering the graphs of these two functions: The first gives more weight to <span class="math notranslate nohighlight">\(x\)</span>-values far away from <span class="math notranslate nohighlight">\(\mu\)</span> as compared to the second, while it gives less weight to <span class="math notranslate nohighlight">\(x\)</span>-values close to <span class="math notranslate nohighlight">\(\mu\)</span> as compared to the second. (Draw the graphs!) These types of considerations are important when one studies <a href="https://en.wikipedia.org/wiki/Loss_function">loss, cost and error functions</a>.</p>
<p>Due to the squaring operation, the units of the variance <span class="math notranslate nohighlight">\(V(X)\)</span> are the units of <span class="math notranslate nohighlight">\(X\)</span> <em>squared</em>. This is sometimes undesirable—for example, if <span class="math notranslate nohighlight">\(X\)</span> is measured in degrees Fahrenheit, then <span class="math notranslate nohighlight">\(V(X)\)</span> is measured in degrees Fahrenheit <em>squared</em>. So, in order to compare apples to apples, sometimes it is more useful to consider the following related measure of dispersion:</p>
<div class="proof definition admonition" id="std-rv-def">
<p class="admonition-title"><span class="caption-number">Definition 4.8 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable. The <em>standard deviation</em> of <span class="math notranslate nohighlight">\(X\)</span>, denoted <span class="math notranslate nohighlight">\(\sigma_X\)</span> or just <span class="math notranslate nohighlight">\(\sigma\)</span>, is the positive square root of the variance:</p>
<div class="math notranslate nohighlight">
\[
\sigma_X = \sqrt{V(X)}.
\]</div>
</section>
</div><p>Let’s compute a few variances and standard deviations straight from the definitions:</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Do problems 21-23 on the worksheet.</p>
</div>
<p>Sometimes the following formula can shorten computations:</p>
<div class="proof theorem admonition" id="shortcut-var-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.5 </span> (Shortcut Formula for Variance)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable. Then</p>
<div class="math notranslate nohighlight">
\[
V(X) = E(X^2) - E(X)^2 =  E(X^2) - \mu_X^2.
\]</div>
</section>
</div><p>Why is this formula true? Here’s why:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
V(X) &amp;= E\left( (X-\mu)^2 \right) \\
&amp;= E \left( X^2 - 2\mu X + \mu^2 \right) \\
&amp;= E(X^2) + E(-2\mu X) +E(\mu^2) \\
&amp;= E(X^2) -2\mu E(X) + \mu^2 \\
&amp;= E(X^2) - 2\mu^2 + \mu^2 \\
&amp;= E(X^2) - \mu^2.
\end{align*}\]</div>
<p>Go through these computations, line by line, and see if you can identify which properties of expectations I used! Be very careful in identifying them!</p>
<p>Now, given a function <span class="math notranslate nohighlight">\(g(X)\)</span> of a random variable <span class="math notranslate nohighlight">\(X\)</span>, the LotUS gives a very simple way to compute the expectation <span class="math notranslate nohighlight">\(E(g(X))\)</span>. We might wish for something similar for variances, but unfortunately things aren’t so simple in general. However, if the function <span class="math notranslate nohighlight">\(g(x)\)</span> is a so-called <em>affine transformation</em> of the form</p>
<div class="math notranslate nohighlight">
\[
g(x) = ax+b,
\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are constants, then we <em>can</em> say something in general:</p>
<div class="proof theorem admonition" id="var-affine-thm">
<p class="admonition-title"><span class="caption-number">Theorem 4.6 </span> (Variance of an Affine Transformation)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable and <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> constants. Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-d49a4e1d-6180-4191-a7b1-e95b9b5eb2f7">
<span class="eqno">(4.18)<a class="headerlink" href="#equation-d49a4e1d-6180-4191-a7b1-e95b9b5eb2f7" title="Permalink to this equation">#</a></span>\[\begin{equation}\notag
V(aX +b) = a^2 V(X).
\end{equation}\]</div>
</section>
</div><p>Why is this formula true? Here’s why:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
V(aX+b) &amp;= E\left( (aX+b)^2 \right) - E(aX+b)^2 \\
&amp;= E\left( a^2 X^2 + 2abX+b^2 \right) - \left(aE(X) + b \right)^2 \\
&amp;= a^2 E(X) + 2ab E(X) + b^2 - a^2 E(X)^2 -2abE(X) - b^2 \\
&amp;= a^2\left( E(X^2) - E(X)^2 \right) \\
&amp;= a^2 V(X).
\end{align*}\]</div>
<p>Again, make sure you can pick out exactly what properties of expectations and variances I used in moving from line to line.</p>
<div class="admonition-problem-prompt admonition">
<p class="admonition-title">Problem Prompt</p>
<p>Holy smokes. After a very, <em>very</em> long discussion of random variables, we’ve finally reached the end! Now finish off the worksheet and do problems 24 and 25.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03-rules-of-prob.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Rules of probability</p>
      </div>
    </a>
    <a class="right-next"
       href="05-examples-of-rvs.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Examples of random variables</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">4.1. Random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-measures-of-random-variables">4.2. Probability measures of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-and-continuous-random-variables">4.3. Discrete and continuous random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-and-quantile-functions">4.4. Distribution and quantile functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-values">4.5. Expected values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-algebra-of-random-variables">4.6. The algebra of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-of-random-variables">4.7. Functions of random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations-of-functions-of-random-variables-and-the-lotus">4.8. Expectations of functions of random variables and the LotUS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linearity-of-expectation">4.9. Linearity of expectation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variances-and-standard-deviations">4.10. Variances and standard deviations</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By John Myers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>