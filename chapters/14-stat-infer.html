
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>14. Statistical inference &#8212; Mathematical Statistics with a View Toward Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "\\operatorname*{argmax}", "argmin": "\\operatorname*{argmin}", "MSE": "\\operatorname*{MSE}", "MAE": "\\operatorname*{MAE}", "Ber": "\\mathcal{B}er", "Cat": "\\mathcal{C}at", "Beta": "\\mathcal{B}eta", "Bin": "\\mathcal{B}in", "def": "\\stackrel{\\text{def}}{=}", "balpha": "\\boldsymbol\\alpha", "bbeta": "\\boldsymbol\\beta", "bdelta": "\\boldsymbol\\delta", "bmu": "\\boldsymbol\\mu", "bfeta": "\\boldsymbol\\eta", "btheta": "\\boldsymbol\\theta", "bpi": "\\boldsymbol\\pi", "bTheta": "\\boldsymbol\\Theta", "bSigma": "\\boldsymbol\\Sigma", "dev": "\\varepsilon", "bbr": "\\mathbb{R}", "ba": "\\mathbf{a}", "bb": "\\mathbf{b}", "bc": "\\mathbf{c}", "bd": "\\mathbf{d}", "be": "\\mathbf{e}", "bf": "\\mathbf{f}", "bg": "\\mathbf{g}", "bp": "\\mathbf{p}", "br": "\\mathbf{r}", "bs": "\\mathbf{s}", "bu": "\\mathbf{u}", "bv": "\\mathbf{v}", "bw": "\\mathbf{w}", "bx": "\\mathbf{x}", "by": "\\mathbf{y}", "bz": "\\mathbf{z}", "bA": "\\mathbf{A}", "bB": "\\mathbf{B}", "bE": "\\mathbf{E}", "bF": "\\mathbf{F}", "bD": "\\mathbf{D}", "bH": "\\mathbf{H}", "bI": "\\mathbf{I}", "bK": "\\mathbf{K}", "bS": "\\mathbf{S}", "bP": "\\mathbf{P}", "bQ": "\\mathbf{Q}", "bW": "\\mathbf{W}", "bX": "\\mathbf{X}", "bY": "\\mathbf{Y}", "bZ": "\\mathbf{Z}", "calJ": "\\mathcal{J}", "calH": "\\mathcal{H}", "calI": "\\mathcal{I}", "calL": "\\mathcal{L}", "calN": "\\mathcal{N}", "calP": "\\mathcal{P}", "calS": "\\mathcal{S}", "Jac": "\\operatorname{Jac}", "thetaMLE": "\\widehat{\\theta}_{\\text{MLE}}", "bthetaMLE": "\\widehat{\\btheta}_{\\text{MLE}}", "thetaMAP": "\\widehat{\\theta}_{\\text{MAP}}", "bthetaMAP": "\\widehat{\\btheta}_{\\text{MAP}}", "hattheta": "\\widehat{\\theta}", "hatbtheta": "\\widehat{\\btheta}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/14-stat-infer';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="15. Bibliography" href="bib.html" />
    <link rel="prev" title="13. Learning" href="13-learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Mathematical Statistics with a View Toward Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Mathematical Statistics with a View Toward Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-preview.html">1. Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-prob-spaces.html">2. Probability spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-rules-of-prob.html">3. Rules of probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-random-variables.html">4. Random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-examples-of-rvs.html">5. Examples of random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-theory-to-practice.html">6. Connecting theory to practice: a first look at model building</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-random-vectors.html">7. Random vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-more-prob.html">8. More probability theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-halfway.html">9. The halfway point: pivoting toward models and data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-info-theory.html">10. Information theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-optim.html">11. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-models.html">12. Probabilistic graphical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-learning.html">13. Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">14. Statistical inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="bib.html">15. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jmyers7/stats-book-materials" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/14-stat-infer.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Statistical inference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-and-their-distributions">14.1. Statistics and their distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-sample-theory">14.2. Large sample theory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-intervals">14.3. Confidence intervals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-tests">14.4. Hypothesis tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-inference-in-linear-regression">14.5. Statistical inference in linear regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-variance">14.6. Analysis of variance</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><strong>THIS CHAPTER IS UNDER CONSTRUCTION!!!</strong></p>
<section class="tex2jax_ignore mathjax_ignore" id="statistical-inference">
<span id="stat-infer"></span><h1><span class="section-number">14. </span>Statistical inference<a class="headerlink" href="#statistical-inference" title="Link to this heading">#</a></h1>
<section id="statistics-and-their-distributions">
<h2><span class="section-number">14.1. </span>Statistics and their distributions<a class="headerlink" href="#statistics-and-their-distributions" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="statistic-def">
<p class="admonition-title"><span class="caption-number">Definition 14.1 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bX\)</span> be a <span class="math notranslate nohighlight">\(m\)</span>-dimensional random vector. A <em>statistic</em> is a random variable of the form</p>
<div class="math notranslate nohighlight">
\[
T = r(\bX),
\]</div>
<p>where <span class="math notranslate nohighlight">\(r:\bbr^m \to \bbr\)</span> is a real-valued function. An observed value <span class="math notranslate nohighlight">\(t\)</span> of <span class="math notranslate nohighlight">\(T\)</span> is called an <em>observed statistic</em> or <em>empirical statistic</em>.</p>
</section>
</div><p>If we conceptualize the components of a random vector <span class="math notranslate nohighlight">\(\bX\)</span> as a dataset <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span>, then a statistic</p>
<div class="math notranslate nohighlight">
\[
T = r(X_1,X_2,\ldots,X_m)
\]</div>
<p>is simply a function of the data. Crucially important examples of statistics include those defined as follows:</p>
<div class="proof definition admonition" id="sample-mean-var-def">
<p class="admonition-title"><span class="caption-number">Definition 14.2 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\bX = (X_1,\ldots,X_m)\)</span> be an <span class="math notranslate nohighlight">\(m\)</span>-dimensional random vector. The <em>sample mean</em> is defined to be the statistic</p>
<div class="math notranslate nohighlight">
\[
\overline{X} \def \frac{1}{m}(X_1+\cdots+X_m),
\]</div>
<p>while the <em>sample variance</em> is defined to be the statistic</p>
<div class="math notranslate nohighlight">
\[
S^2 \def \frac{1}{m-1} \sum_{i=1}^m(X_i - \overline{X})^2.
\]</div>
<p>The corresponding empirical statistics are the <em>empirical mean</em> and <em>empirical variance</em> defined as</p>
<div class="math notranslate nohighlight">
\[
\overline{x} \def \frac{1}{m}(x_1+\cdots+x_m) \quad \text{and} \quad s^2 = \frac{1}{m-1} \sum_{i=1}^m(x_i - \overline{x})^2.
\]</div>
</section>
</div><p>Very often, the component random variables <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> of the random vector <span class="math notranslate nohighlight">\(\bX\)</span> in the definition are assumed to form a random sample, i.e., an IID sequence of random variables. The dimension <span class="math notranslate nohighlight">\(m\)</span> is then referred to as the <em>sample size</em>. In principle, then, the sample size <span class="math notranslate nohighlight">\(m\)</span> can be <em>any</em> positive integer, and so it is often convenient to write <span class="math notranslate nohighlight">\(\overline{X}_m\)</span> for the sample mean, explicitly displaying the sample size. This gives us an entire <em>infinite sequence</em> of sample means:</p>
<div class="math notranslate nohighlight" id="equation-seq-means-eqn">
<span class="eqno">(14.1)<a class="headerlink" href="#equation-seq-means-eqn" title="Link to this equation">#</a></span>\[
\overline{X}_1,\overline{X}_2,\ldots,\overline{X}_m, \ldots.
\]</div>
<p>Since statistics are random vectors, they have their own probability distributions. These are given special names:</p>
<div class="proof definition admonition" id="samp-dist-def">
<p class="admonition-title"><span class="caption-number">Definition 14.3 </span></p>
<section class="definition-content" id="proof-content">
<p>The probability distribution of a statistic <span class="math notranslate nohighlight">\(T\)</span> is called the <em>sampling distribution</em> of <span class="math notranslate nohighlight">\(T\)</span>.</p>
</section>
</div><p>The sampling distributions for sample means <span class="math notranslate nohighlight">\(\overline{X}_m\)</span> are particularly important, and one of the main goals of <a class="reference internal" href="#large-sample"><span class="std std-numref">Section 14.2</span></a> is to study the limiting behavior (or <em>asymptotic behavior</em>) of the sampling distributions in the sequence <a class="reference internal" href="#equation-seq-means-eqn">(14.1)</a> as <span class="math notranslate nohighlight">\(m\to \infty\)</span>.</p>
<p>In general, however, computing the sampling distributions is difficult. But if we actually have <em>observed</em> data <span class="math notranslate nohighlight">\(x_1,x_2,\ldots,x_m\)</span>, then (as you will explore in the programming assignment) there is a resampling method known as <em>bootstrapping</em> that yields  approximations to sampling distributions. An example is given by the histogram (with KDE) on the right-hand side of the following figure, where a histogram (with KDE) of the empirical distribution of an observed dataset is given on the left-hand side:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline.backend_inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span> <span class="k">as</span> <span class="nn">clr</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../aux-files/custom_style_light.mplstyle&#39;</span><span class="p">)</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">blue</span> <span class="o">=</span> <span class="s1">&#39;#486AFB&#39;</span>
<span class="n">magenta</span> <span class="o">=</span> <span class="s1">&#39;#FD46FC&#39;</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">resample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">random_sample</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">replicate_means</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_resamples</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_resamples</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">random_sample</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">resample_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">replicate_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">random_sample</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">replicate_means</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;density&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;observed data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;density&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;bootstrap sampling distribution of sample mean&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<figure class="align-center">
<img alt="../_images/4be4d28d5a53380fde24e9b485a825745776be9cefd2fcb606bc78440b07e645.svg" src="../_images/4be4d28d5a53380fde24e9b485a825745776be9cefd2fcb606bc78440b07e645.svg" /></figure>
</div>
</div>
<p>Observe that the sampling distribution on the right-hand side appears to be well approximated by a normal distribution. This is actually a manifestation of the asymptotic behavior of sample means that we alluded to above; indeed, as we will see in <a class="reference internal" href="#large-sample"><span class="std std-numref">Section 14.2</span></a>, the Central Limit Theorem tells us that the sequence <a class="reference internal" href="#equation-seq-means-eqn">(14.1)</a> of sample means converges (in distribution) to a normal distribution as <span class="math notranslate nohighlight">\(m\to \infty\)</span>, provided that the random variables are IID. This is true even though the observed data are definitely <em>not</em> normally distributed. Moreover, the mean of the sampling distribution is approximately <span class="math notranslate nohighlight">\(4.924\)</span>, while the mean of the observed data is approximately <span class="math notranslate nohighlight">\(4.928\)</span>. The fact that these means are nearly equal is a consequence of another theorem in <a class="reference internal" href="#large-sample"><span class="std std-numref">Section 14.2</span></a> called the Law of Large Numbers.</p>
<p>Let’s consider the sample mean a little closer:</p>
<div class="proof theorem admonition" id="prop-sample-mean-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.1 </span> (Properties of the sample mean)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<ol class="arabic simple">
<li><p>The expectation of the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>The variance of the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is <span class="math notranslate nohighlight">\(\sigma^2/m\)</span>, and hence its standard deviation is <span class="math notranslate nohighlight">\(\sigma/\sqrt{m}\)</span>.</p></li>
<li><p>If the <span class="math notranslate nohighlight">\(X_i\)</span>’s are normally distributed, then so too is the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span>.</p></li>
</ol>
</section>
</div></section>
<section id="large-sample-theory">
<span id="large-sample"></span><h2><span class="section-number">14.2. </span>Large sample theory<a class="headerlink" href="#large-sample-theory" title="Link to this heading">#</a></h2>
<div class="proof theorem admonition" id="clt-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.2 </span> (Central Limit Theorem)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>. Then, in the limit as <span class="math notranslate nohighlight">\(m\to \infty\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
\lim_{m\to \infty} P \left( \frac{\overline{X} - \mu}{\sigma/\sqrt{m}} \leq z \right) = P(Z \leq z) = \Phi(z),
\]</div>
<p>where <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0,1)\)</span>.</p>
</section>
</div></section>
<section id="confidence-intervals">
<span id="cis"></span><h2><span class="section-number">14.3. </span>Confidence intervals<a class="headerlink" href="#confidence-intervals" title="Link to this heading">#</a></h2>
<div class="proof theorem admonition" id="standardized-mean-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.3 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>. Then the statistic</p>
<div class="math notranslate nohighlight">
\[
\frac{\overline{X} - \mu}{\sqrt/\sqrt{m}}
\]</div>
<p>has a standard normal distribution. This statistic is called the <em>standardized mean</em>.</p>
</section>
</div><div class="proof theorem admonition" id="CI-norm-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.4 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a normal distribution with <strong>unknown</strong> mean <span class="math notranslate nohighlight">\(\mu\)</span> and <strong>known</strong> standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, and let <span class="math notranslate nohighlight">\(\bar{x}\)</span> be the empirical mean computed from an observed random sample. For <span class="math notranslate nohighlight">\(\alpha\in [0,1]\)</span>, the interval</p>
<div class="math notranslate nohighlight">
\[
\left(\bar{x} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}}, \bar{x} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}} \right)
\]</div>
<p>is a <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval for the mean <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</section>
</div><div class="proof theorem admonition" id="CI-large-sample-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.5 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a distribution with <strong>unknown</strong> mean <span class="math notranslate nohighlight">\(\mu\)</span> and <strong>known</strong> standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, and let <span class="math notranslate nohighlight">\(\bar{x}\)</span> be the empirical mean computed from an observed random sample. For <span class="math notranslate nohighlight">\(\alpha\in [0,1]\)</span> and <span class="math notranslate nohighlight">\(m\)</span> sufficiently large, the random interval</p>
<div class="math notranslate nohighlight">
\[
\left(\bar{x} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}}, \bar{x} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}} \right)
\]</div>
<p>is approximately a <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval for the mean <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="t-dist-defn">
<p class="admonition-title"><span class="caption-number">Definition 14.4 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\nu\geq 1\)</span> be an integer. A continuous random variable <span class="math notranslate nohighlight">\(X\)</span> is said to have a <em><span class="math notranslate nohighlight">\(t\)</span>-distribution with <span class="math notranslate nohighlight">\(\nu\)</span> degrees of freedom</em>, denoted</p>
<div class="math notranslate nohighlight">
\[
X \sim t_{\nu},
\]</div>
<p>if its probability density function is given by</p>
<div class="math notranslate nohighlight">
\[
f(x;\nu) = \frac{\Gamma\left(\frac{\nu+1}{2} \right)}{\Gamma\left( \frac{\nu}{2} \right) \sqrt{\nu\pi}}\left(1 + \frac{x^2}{\nu} \right)^{- \frac{\nu+1}{2}}
\]</div>
<p>with support <span class="math notranslate nohighlight">\(\bbr\)</span>.</p>
</section>
</div><div class="proof theorem admonition" id="student-mean-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.6 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, and let <span class="math notranslate nohighlight">\(\bar{x}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> be the empirical mean and standard deviation computed from an observed random sample. Then the statistic</p>
<div class="math notranslate nohighlight">
\[
\frac{\overline{X} - \mu}{s/\sqrt{m}}
\]</div>
<p>has a <span class="math notranslate nohighlight">\(t_{m-1}\)</span> distribution. This statistic is called the <em>studentized mean</em>.</p>
</section>
</div><div class="proof theorem admonition" id="t-CI-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.7 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1,X_2,\ldots,X_m\)</span> be an IID random sample from a normal distribution with <strong>unknown</strong> mean <span class="math notranslate nohighlight">\(\mu\)</span> and <strong>unknown</strong> standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, and let <span class="math notranslate nohighlight">\(\bar{x}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> be the empirical mean and standard deviation computed from an observed random sample. For <span class="math notranslate nohighlight">\(\alpha \in [0,1]\)</span>, the interval</p>
<div class="math notranslate nohighlight">
\[
\left( \overline{x} - t_{\alpha/2, m-1} \cdot \frac{s}{\sqrt{m}}, \overline{x} + t_{\alpha/2, m-1} \cdot \frac{s}{\sqrt{m}} \right)
\]</div>
<p>is a <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval for the mean <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</section>
</div></section>
<section id="hypothesis-tests">
<h2><span class="section-number">14.4. </span>Hypothesis tests<a class="headerlink" href="#hypothesis-tests" title="Link to this heading">#</a></h2>
</section>
<section id="statistical-inference-in-linear-regression">
<h2><span class="section-number">14.5. </span>Statistical inference in linear regression<a class="headerlink" href="#statistical-inference-in-linear-regression" title="Link to this heading">#</a></h2>
<p>Consider a simple linear regression model with parameters <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Given an observed dataset</p>
<div class="math notranslate nohighlight">
\[
(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m) \in \bbr^2,
\]</div>
<p>we saw in <a class="reference internal" href="13-learning.html#mle-simple-lin-reg-cor">Corollary 13.1</a> that the maximum likelihood estimates</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_0 \def (\beta_0)_\text{MLE}^\star \quad \text{and} \quad \hat{\beta}_1 \def (\beta_1)_\text{MLE}^\star
\]</div>
<p>for the “true” bias and slope terms <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> are</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_1 = \frac{\sum_{i=1}^m \left(x_i - \bar{x} \right)\left( y_i - \bar{y} \right)}{\sum_{i=1}^m \left(x_i - \bar{x} \right)^2} \quad \text{and} \quad \hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}.
\]</div>
<p>We also defined the <em>predicted values</em> and <em>residuals</em> by the equations</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = \beta_0 + \beta_1 x_i \quad \text{and} \quad r_i = y_i - \hat{y}_i.
\]</div>
<p>These definitions of <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> and <span class="math notranslate nohighlight">\(r_i\)</span> suited our brief analysis in <a class="reference internal" href="12-models.html#prob-models"><span class="std std-numref">Chapter 12</span></a>. However, in order to obtain their values, we would need to know the “true” values of <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>, which we presumably don’t know! So, our discussion in this section begins with alternate definitions of these quantities based on the MLEs for the bias and slope terms:</p>
<div class="proof definition admonition" id="predict-resid-defn">
<p class="admonition-title"><span class="caption-number">Definition 14.5 </span></p>
<section class="definition-content" id="proof-content">
<p>Letting the notation be as above, we define the <em><span class="math notranslate nohighlight">\(i\)</span>-th predicted value</em> and <em><span class="math notranslate nohighlight">\(i\)</span>-th residual</em> to be</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i \quad \text{and} \quad r_i = y_i - \hat{y}_i,
\]</div>
<p>for each <span class="math notranslate nohighlight">\(i=1,2,\ldots,m\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="ss-defn">
<p class="admonition-title"><span class="caption-number">Definition 14.6 </span></p>
<section class="definition-content" id="proof-content">
<p>We define</p>
<div class="math notranslate nohighlight">
\[
RSS = \sum_{i=1}^m (y_i - \hat{y}_i)^2, \quad TSS = \sum_{i=1}^m (y_i - \hat{y})^2, \quad RSE = \sqrt{ \frac{SSE}{n-2}}.
\]</div>
<p>Then also:</p>
<div class="math notranslate nohighlight">
\[
R^2 = 1 - \frac{RSS}{TSS}.
\]</div>
</section>
</div><div class="proof theorem admonition" id="slope-estimator-thm">
<p class="admonition-title"><span class="caption-number">Theorem 14.8 </span></p>
<section class="theorem-content" id="proof-content">
<p>Consider a linear regression model with parameters <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Let <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> be the slope estimator defined in <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">slope-estimator-defn</span></code>.</p>
<ol class="arabic simple">
<li><p>We have <span class="math notranslate nohighlight">\(E(\hat{\beta}_1) = \beta_1\)</span>.</p></li>
<li><p>We have <span class="math notranslate nohighlight">\(V(\hat{\beta}_1) = \sigma^2 / S_{xx}\)</span>.</p></li>
<li><p>The sampling distribution of <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> is normal.</p></li>
</ol>
</section>
</div></section>
<section id="analysis-of-variance">
<h2><span class="section-number">14.6. </span>Analysis of variance<a class="headerlink" href="#analysis-of-variance" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="categorical-defn">
<p class="admonition-title"><span class="caption-number">Definition 14.7 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(n\geq 1\)</span> be an integer and let <span class="math notranslate nohighlight">\(\btheta^\intercal =(\theta_1,\ldots,\theta_n)\)</span> be a vector such that <span class="math notranslate nohighlight">\(0\leq \theta_j \leq 1\)</span> for each <span class="math notranslate nohighlight">\(j=1,\ldots,n\)</span> and <span class="math notranslate nohighlight">\(\sum_{j=1}^n \theta_j = 1\)</span>. A discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is said to have a <em>categorical distribution</em> with parameter <span class="math notranslate nohighlight">\(\btheta\)</span>, denoted</p>
<div class="math notranslate nohighlight">
\[
X \sim \Cat(\btheta),
\]</div>
<p>if its probability mass function is given by</p>
<div class="math notranslate nohighlight">
\[
p(x;\btheta) = \theta_x
\]</div>
<p>if <span class="math notranslate nohighlight">\(x\in \{1,2,\ldots,n\}\)</span>, and <span class="math notranslate nohighlight">\(p(x;\btheta)=0\)</span> otherwise.</p>
</section>
</div><div class="proof definition admonition" id="anova-defn">
<p class="admonition-title"><span class="caption-number">Definition 14.8 </span></p>
<section class="definition-content" id="proof-content">
<p>An <em>analysis of variance model</em>, or <em>ANOVA model</em>, is a probabilistic graphical model whose underlying graph is of the form</p>
<a class="reference internal image-reference" href="../_images/anova.svg"><img alt="../_images/anova.svg" class="align-center" src="../_images/anova.svg" width="25%" /></a>
<p> </p>
<p>The model has the following parameters:</p>
<ul class="simple">
<li><p>A parameter vector <span class="math notranslate nohighlight">\(\btheta \in \bbr^n\)</span> such that <span class="math notranslate nohighlight">\(X \sim \Cat(\btheta)\)</span>.</p></li>
<li><p>A parameter vector <span class="math notranslate nohighlight">\(\bmu \in \bbr^n\)</span>.</p></li>
<li><p>A positive real parameter <span class="math notranslate nohighlight">\(\sigma^2&gt;0\)</span>.</p></li>
</ul>
<p>The link function at <span class="math notranslate nohighlight">\(Y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
Y \mid X \sim \mathcal{N}(\mu,\sigma^2), \quad \text{where} \quad \mu = \mu(x) = \mu_x,
\]</div>
<p>and <span class="math notranslate nohighlight">\(\bmu^\intercal = (\mu_1,\mu_2,\ldots,\mu_{n})\)</span>.</p>
</section>
</div></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="13-learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">13. </span>Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="bib.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-and-their-distributions">14.1. Statistics and their distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-sample-theory">14.2. Large sample theory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-intervals">14.3. Confidence intervals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-tests">14.4. Hypothesis tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-inference-in-linear-regression">14.5. Statistical inference in linear regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-variance">14.6. Analysis of variance</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By John Myers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>